{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4T6QHHOnfcQ"
   },
   "source": [
    "# Part 1: Build CpG Detector\n",
    "\n",
    "Here we have a simple problem, given a DNA sequence (of N, A, C, G, T), count the number of CpGs in the sequence (consecutive CGs).\n",
    "\n",
    "We have defined a few helper functions / parameters for performing this task.\n",
    "\n",
    "We need you to build a LSTM model and train it to complish this task in PyTorch.\n",
    "\n",
    "A good solution will be a model that can be trained, with high confidence in correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The overall process of building the solution is as follows:\n",
    "- We perform similar options for Fixed Length and Variable Length sequences.\n",
    "\n",
    "    ##### Fixed Length Sequences:\n",
    "\n",
    "    ##### Simple:\n",
    "    - We start with a custom Pytorch dataset which will process the data and return the input and output tensors.If the sequences are of varying lengths, we will pad them with zeros to make them of the same length.\n",
    "    - We will use the Pytorch DataLoader to load the data in batches and using the padding collate function to pad the sequences at batch level.\n",
    "    - We will use a simple LSTM model `CpGCounter` to predict the next token in the sequence which is a basic model with an LSTM layer and a linear layer.\n",
    "    - We have training loop and evaluation loop to train and evaluate the model and we have used optimizer `AdamW` loss `MSELoss` and lr scheduler `ReduceLROnPlateau`\n",
    "    - We have used `mse` and `rmse` as metrics to evaluate the model.\n",
    "    - We have used `early stopping` to stop the training if the model is not improving.\n",
    "    \n",
    "    ##### Advanced:\n",
    "    - We will use a more complex model `CpGCounterAdvanced` which has an LSTM layer, a linear layer and and regularization layer `Dropout` to prevent overfitting.\n",
    "    - We will use `AdamW` optimizer, `MSELoss` loss and `ReduceLROnPlateau` lr scheduler and also gradient clipping to prevent exploding gradients and gradient scaler and autocast\n",
    "    - We have used `mse` and `rmse` as metrics to evaluate the model.\n",
    "    - We have used `early stopping` to stop the training if the model is not improving.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mfS4cLmZD2oB"
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from functools import partial\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_f-brPAvKvTn"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE (Original as per the assignment)\n",
    "def set_seed(seed=13):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence(n_seqs: int, seq_len: int = 128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        yield [random.randint(0, 4) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i : i + 2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers\n",
    "alphabet = \"NACGT\"\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(5))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(5))}\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1651686469847,
     "user": {
      "displayName": "Ylex",
      "userId": "01820639168093643789"
     },
     "user_tz": 240
    },
    "id": "VK9Qg5GHYxOb",
    "outputId": "0a00bbb6-d9ac-4cf8-ed84-b55b335d7f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total length of X_dna_seqs_train is 2048\n",
      "The total length of y_dna_seqs is 2048\n",
      "The total length of X_dna_seqs_train is 512\n",
      "The total length of y_dna_seqs is 512\n"
     ]
    }
   ],
   "source": [
    "# we stick to the original function signature\n",
    "def prepare_data(num_samples=100):\n",
    "    # prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence(num_samples))\n",
    "    print(f\"The total length of X_dna_seqs_train is {len(X_dna_seqs_train)}\")\n",
    "    \"\"\"\n",
    "    hint:\n",
    "        1. You can check X_dna_seqs_train by print, the data is ids which is your training X \n",
    "        2. You first convert ids back to DNA sequence\n",
    "        3. Then you run count_cpgs which will yield CGs counts - this will be the labels (Y)\n",
    "    \"\"\"\n",
    "    # step2\n",
    "    temp = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "    # temp is basically the a list of DNA sequences and each sequence is a string\n",
    "    # step3\n",
    "    y_dna_seqs = [count_cpgs(seq) for seq in temp]\n",
    "    # y_dna_seqs is basically the count of CGs in each DNA sequence\n",
    "    print(f\"The total length of y_dna_seqs is {len(y_dna_seqs)}\")\n",
    "\n",
    "    return X_dna_seqs_train, y_dna_seqs\n",
    "\n",
    "\n",
    "train_x, train_y = prepare_data(2048)\n",
    "test_x, test_y = prepare_data(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 0, 'A': 1, 'C': 2, 'G': 3, 'T': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_23_pairs(lst, n1=3, n2=4):\n",
    "#     count = 0\n",
    "#     for i in range(len(lst) - 1):\n",
    "#         if lst[i] == n1 and lst[i + 1] == n2:\n",
    "#             count += 1\n",
    "#     return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y[9], count_23_pairs(train_x[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128 128 128\n",
      "2048 512\n"
     ]
    }
   ],
   "source": [
    "# each sequence has a length of 128 and the total number of sequences is 2048 and 512 for train and test respectively\n",
    "print(\n",
    "    min(map(len, train_x)),\n",
    "    max(map(len, train_x)),\n",
    "    min(map(len, test_x)),\n",
    "    max(map(len, test_x)),\n",
    ")\n",
    "print(len(train_x), len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -----------------Hyperparameters----------------- #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "embedding_dim = 64\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "weight_decay = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "stop_patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(dna2int)\n",
    "print(vocab_size)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from typing import Tuple, List\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -------------------------Pytorch Custom Dataset and Dataloader-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPGDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with sequences and labels (CpG counts) as input arguments and store them as attributes.\n",
    "\n",
    "        Parameters:\n",
    "        - sequences (List[List[int]]): List of integer-encoded DNA sequences.\n",
    "        - labels (List[int]): List of CpG counts corresponding to each sequence.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.sequences = [torch.tensor(seq, dtype=torch.long) for seq in sequences]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of sequences in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a sequence and its label by index.\n",
    "        \"\"\"\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"\n",
    "        Custom collate function to pad sequences dynamically and return a batch of sequences and labels.\n",
    "        \"\"\"\n",
    "        sequences, labels = zip(*batch)\n",
    "        padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "        return padded_sequences, torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch standard dataset\n",
    "train_dataset = CPGDataset(train_x, train_y)\n",
    "val_dataset = CPGDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# each iteration of the dataset will return a list of sequences and a labels\n",
    "x, y = next(iter(train_dataset))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch standard dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDataset.collate_fn,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# each iteration of the dataloader will return a batch of sequences and labels\n",
    "for x_batch, y_batch in train_dataloader:\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break\n",
    "\n",
    "for x_batch, y_batch in val_dataloader:\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Notes:\n",
    "* We are using a collate function to pad the sequences dynamically which will be used in the dataloader to return a padded batch of sequences and labels.\n",
    "* Even if the sequences are of different lengths, the collate function will pad them to the same length.\n",
    "* The sequences are stored as a list of tensors and the labels are stored as a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic LSTM model #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "q8fgxrM0LnLy"
   },
   "outputs": [],
   "source": [
    "class CpGCounter(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialize the CpGCounter model with the given hyperparameters and layers.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size (int): Number of unique tokens in the input sequences.\n",
    "        - embedding_dim (int): Dimension of the embedding layer.\n",
    "        - hidden_size (int): Dimension of the hidden state in the LSTM layer.\n",
    "        - num_layers (int): Number of LSTM layers.\n",
    "        - dropout (float): Dropout rate to apply between LSTM layers.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        super(CpGCounter, self).__init__()\n",
    "        # Embedding layer to convert integer-encoded sequences to embeddings of fixed size (embedding_dim)\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0\n",
    "        )  # input: (batch_size, seq_len), output: (batch_size, seq_len, embedding_dim)\n",
    "        # LSTM layer to process the embeddings and capture sequential information (hidden_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0\n",
    "        )  # input: (batch_size, seq_len, embedding_dim), output: (batch_size, seq_len, hidden_size)\n",
    "        # Fully connected layer to predict the number of CpG sites\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_size, 1\n",
    "        )  # input: (batch_size, seq_len, hidden_size), output: (batch_size, seq_len, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the CpGCounter model.\n",
    "\n",
    "        Parameters:\n",
    "        - x (torch.Tensor): Input sequences with shape (batch_size, seq_len).\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Predicted CpG counts for each sequence in the batch.\n",
    "        \"\"\"\n",
    "\n",
    "        assert (\n",
    "            torch.max(x).item() < self.embedding.num_embeddings\n",
    "        ), \"Index out of range!\"\n",
    "        # Embed the input sequences\n",
    "        embedded = self.embedding(x)\n",
    "        # Process the embeddings with an LSTM layer\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "        # we only take the last hidden state\n",
    "        lstm_output = lstm_output[\n",
    "            :, -1, :\n",
    "        ]  # shape is (batch_size, hidden_size) and we only take the last hidden state of the sequence\n",
    "        # Predict the number of CpG sites\n",
    "        output = self.fc(lstm_output)\n",
    "        return self.relu(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions #####\n",
    "* Training loop: A function to train the model for one epoch.\n",
    "* Evaluation loop: A function to evaluate the model on the validation set.\n",
    "* Training function: A function to train the model for multiple epochs.\n",
    "* Checkpoint functions: Functions to save and load model checkpoints.\n",
    "* Inference function: A function to get predictions from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, device, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Runs one training epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to train.\n",
    "    - dataloader (DataLoader): Training DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss (float): Average loss over dataset.\n",
    "    - avg_mae (float): Average MAE over dataset.\n",
    "    - avg_rmse (float): Average RMSE over dataset.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mae, total_rmse = 0.0, 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = (\n",
    "            inputs.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute batch-wise metrics\n",
    "        batch_mae = mean_absolute_error(\n",
    "            labels.cpu().numpy(), outputs.detach().cpu().numpy()\n",
    "        )\n",
    "        batch_rmse = (\n",
    "            mean_squared_error(labels.cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "            ** 0.5\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mae += batch_mae\n",
    "        total_rmse += batch_rmse\n",
    "\n",
    "    return total_loss / num_batches, total_mae / num_batches, total_rmse / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, dataloader, device, criterion):\n",
    "    \"\"\"\n",
    "    Runs one validation epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to evaluate.\n",
    "    - dataloader (DataLoader): Validation DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss (float): Average loss over dataset.\n",
    "    - avg_mae (float): Average MAE over dataset.\n",
    "    - avg_rmse (float): Average RMSE over dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_mae, total_rmse = 0.0, 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = (\n",
    "                inputs.to(device),\n",
    "                labels.to(device),\n",
    "            )\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute batch-wise metrics\n",
    "            batch_mae = mean_absolute_error(labels.cpu().numpy(), outputs.cpu().numpy())\n",
    "            batch_rmse = (\n",
    "                mean_squared_error(labels.cpu().numpy(), outputs.cpu().numpy()) ** 0.5\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mae += batch_mae\n",
    "            total_rmse += batch_rmse\n",
    "\n",
    "    return total_loss / num_batches, total_mae / num_batches, total_rmse / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    epoch, model, optimizer, scheduler, best_val_loss, save_path=\"best_cpg_model.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves the model, optimizer, and scheduler state for training resumption.\n",
    "\n",
    "    Parameters:\n",
    "    - epoch (int): Current epoch number.\n",
    "    - model (nn.Module): PyTorch model to save.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer to save.\n",
    "    - scheduler (torch.optim.lr_scheduler): Scheduler to save.\n",
    "    - best_val_loss (float): Best validation loss achieved.\n",
    "    - save_path (str): Path to save the checkpoint.\n",
    "\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,  # Save next epoch to resume correctly\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Model checkpoint saved at {save_path}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(\n",
    "    model, optimizer, scheduler, device, save_path=\"best_cpg_model.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads a saved checkpoint to resume training.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to load the state_dict into.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer to load the state_dict into.\n",
    "    - scheduler (torch.optim.lr_scheduler): Scheduler to load the state_dict into.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - save_path (str): Path to the saved checkpoint.\n",
    "    \n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(save_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "    best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "\n",
    "    print(\n",
    "        f\"Loaded checkpoint from {save_path}, resuming from epoch {checkpoint['epoch']} with best validation loss: {best_val_loss:.4f}\"\n",
    "    )\n",
    "    return model, optimizer, scheduler, checkpoint[\"epoch\"], best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=25,\n",
    "    patience=5,\n",
    "    save_path=\"best_cpg_model.pth\",\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    resume=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model with validation and early stopping. Supports resuming training.\n",
    "\n",
    "    Parameters:\n",
    "    - model: LSTM model.\n",
    "    - train_loader: Training DataLoader.\n",
    "    - val_loader: Validation DataLoader.\n",
    "    - device: CPU or GPU.\n",
    "    - epochs: Max training epochs.\n",
    "    - patience: Early stopping patience.\n",
    "    - save_path: Path to save the best model.\n",
    "    - lr: Initial learning rate.\n",
    "    - weight_decay: L2 regularization weight.\n",
    "    - resume: Whether to resume training from the last checkpoint.\n",
    "\n",
    "    Returns:\n",
    "    - Best trained model.\n",
    "    \"\"\"\n",
    "    # initialize model and optimizer and scheduler and criterion and best_val_loss and start_epoch\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "    )\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if resuming\n",
    "    if resume and os.path.exists(save_path):\n",
    "        try:\n",
    "            model, optimizer, scheduler, start_epoch, best_val_loss = load_checkpoint(\n",
    "                model, optimizer, scheduler, device, save_path\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Starting training from scratch.\")\n",
    "\n",
    "    no_improvement = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            train_loss, train_mae, train_rmse = training_loop(\n",
    "                model, train_loader, device, optimizer, criterion\n",
    "            )\n",
    "            val_loss, val_mae, val_rmse = validation_loop(\n",
    "                model, val_loader, device, criterion\n",
    "            )\n",
    "\n",
    "            # Scheduler step\n",
    "            if epoch > 0:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "            # Print results\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.4f}, Train RMSE: {train_rmse:.4f}, \"\n",
    "                f\"Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}, Val RMSE: {val_rmse:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Save best model checkpoint\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\n",
    "                    f\"New best validation loss: {val_loss:.4f} (previous best: {best_val_loss:.4f})\"\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "                save_checkpoint(\n",
    "                    epoch, model, optimizer, scheduler, best_val_loss, save_path\n",
    "                )\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                print(f\"No improvement, patience left: {patience - no_improvement}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if no_improvement >= patience:\n",
    "                print(f\"Early Stopping Triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training Interrupted! Saving last checkpoint...\")\n",
    "        save_checkpoint(epoch, model, optimizer, scheduler, best_val_loss, save_path)\n",
    "\n",
    "    print(f\"Training Completed in {(time.time() - start_time):.2f} seconds\")\n",
    "\n",
    "    # Load the best model before returning\n",
    "    model, optimizer, scheduler, _, _ = load_checkpoint(\n",
    "        model, optimizer, scheduler, device, save_path\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cpgs_from_dna(\n",
    "    model_path: str,\n",
    "    dna_sequence: str,\n",
    "    dna2int: dict,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounter,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict CpG count from a human DNA string.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to trained LSTM model.\n",
    "    - dna_sequence: Human-readable DNA string.\n",
    "    - dna2int: Dictionary mapping DNA bases to integer values.\n",
    "    - embedding_dim: Dimension of embedding layer.\n",
    "    - hidden_size: Size of LSTM hidden state.\n",
    "    - num_layers: Number of LSTM layers.\n",
    "    - dropout: Dropout rate.\n",
    "    - device: The device ('cpu' or 'cuda') for inference.\n",
    "    - model_class: Model class to use for inference.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted CpG count (rounded to 2 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the model checkpoint exists\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {model_path}\")\n",
    "\n",
    "    # Load Model\n",
    "    vocab_size = len(dna2int)\n",
    "    model = model_class(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "    # Load the trained model checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)  # Move model to the correct device\n",
    "    model.eval()\n",
    "\n",
    "    # Convert DNA string to integer sequence\n",
    "    int_sequence = [\n",
    "        dna2int.get(base, 0) for base in dna_sequence\n",
    "    ]  # Map bases to integers\n",
    "    # print(int_sequence)\n",
    "    int_tensor = (\n",
    "        torch.tensor(int_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    )  # Move to same device\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        predicted_count = model(int_tensor).squeeze().item()  # Ensure it's a scalar\n",
    "\n",
    "    return round(predicted_count, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpGCounter(\n",
      "  (embedding): Embedding(5, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "new_model = CpGCounter(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    ")\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 1/100, Train Loss: 6.5828, Train MAE: 1.9894, Train RMSE: 2.3758, Val Loss: 4.1894, Val MAE: 1.6242, Val RMSE: 2.0227\n",
      "New best validation loss: 4.1894 (previous best: inf)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 2/100, Train Loss: 4.2484, Train MAE: 1.6438, Train RMSE: 2.0328, Val Loss: 4.2041, Val MAE: 1.6323, Val RMSE: 2.0264\n",
      "No improvement, patience left: 9\n",
      "Epoch 3/100, Train Loss: 4.2388, Train MAE: 1.6415, Train RMSE: 2.0304, Val Loss: 4.2629, Val MAE: 1.6582, Val RMSE: 2.0411\n",
      "No improvement, patience left: 8\n",
      "Epoch 4/100, Train Loss: 4.2322, Train MAE: 1.6407, Train RMSE: 2.0290, Val Loss: 4.2086, Val MAE: 1.6358, Val RMSE: 2.0279\n",
      "No improvement, patience left: 7\n",
      "Epoch 5/100, Train Loss: 4.2037, Train MAE: 1.6381, Train RMSE: 2.0226, Val Loss: 4.5284, Val MAE: 1.7263, Val RMSE: 2.1048\n",
      "No improvement, patience left: 6\n",
      "Epoch 6/100, Train Loss: 4.2467, Train MAE: 1.6510, Train RMSE: 2.0343, Val Loss: 4.1592, Val MAE: 1.5879, Val RMSE: 2.0151\n",
      "New best validation loss: 4.1592 (previous best: 4.1894)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 7/100, Train Loss: 4.1547, Train MAE: 1.6268, Train RMSE: 2.0113, Val Loss: 4.1379, Val MAE: 1.5900, Val RMSE: 2.0096\n",
      "New best validation loss: 4.1379 (previous best: 4.1592)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 8/100, Train Loss: 3.9205, Train MAE: 1.5828, Train RMSE: 1.9527, Val Loss: 3.1225, Val MAE: 1.3779, Val RMSE: 1.7460\n",
      "New best validation loss: 3.1225 (previous best: 4.1379)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 9/100, Train Loss: 2.4377, Train MAE: 1.2341, Train RMSE: 1.5316, Val Loss: 1.7603, Val MAE: 1.0450, Val RMSE: 1.3172\n",
      "New best validation loss: 1.7603 (previous best: 3.1225)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 10/100, Train Loss: 1.1949, Train MAE: 0.8352, Train RMSE: 1.0633, Val Loss: 0.8824, Val MAE: 0.7181, Val RMSE: 0.9270\n",
      "New best validation loss: 0.8824 (previous best: 1.7603)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 11/100, Train Loss: 0.7061, Train MAE: 0.6469, Train RMSE: 0.8191, Val Loss: 0.7379, Val MAE: 0.6667, Val RMSE: 0.8452\n",
      "New best validation loss: 0.7379 (previous best: 0.8824)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 12/100, Train Loss: 0.4921, Train MAE: 0.5342, Train RMSE: 0.6788, Val Loss: 0.3300, Val MAE: 0.4402, Val RMSE: 0.5573\n",
      "New best validation loss: 0.3300 (previous best: 0.7379)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 13/100, Train Loss: 0.3223, Train MAE: 0.4343, Train RMSE: 0.5493, Val Loss: 0.2738, Val MAE: 0.3980, Val RMSE: 0.5065\n",
      "New best validation loss: 0.2738 (previous best: 0.3300)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 14/100, Train Loss: 0.2676, Train MAE: 0.3932, Train RMSE: 0.5015, Val Loss: 0.1801, Val MAE: 0.3091, Val RMSE: 0.4057\n",
      "New best validation loss: 0.1801 (previous best: 0.2738)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 15/100, Train Loss: 0.2274, Train MAE: 0.3660, Train RMSE: 0.4607, Val Loss: 0.1603, Val MAE: 0.2915, Val RMSE: 0.3849\n",
      "New best validation loss: 0.1603 (previous best: 0.1801)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 16/100, Train Loss: 0.1835, Train MAE: 0.3267, Train RMSE: 0.4146, Val Loss: 0.1885, Val MAE: 0.3343, Val RMSE: 0.4236\n",
      "No improvement, patience left: 9\n",
      "Epoch 17/100, Train Loss: 0.1573, Train MAE: 0.3011, Train RMSE: 0.3823, Val Loss: 0.1170, Val MAE: 0.2536, Val RMSE: 0.3309\n",
      "New best validation loss: 0.1170 (previous best: 0.1603)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 18/100, Train Loss: 0.1275, Train MAE: 0.2709, Train RMSE: 0.3426, Val Loss: 0.0985, Val MAE: 0.2229, Val RMSE: 0.3006\n",
      "New best validation loss: 0.0985 (previous best: 0.1170)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 19/100, Train Loss: 0.1163, Train MAE: 0.2583, Train RMSE: 0.3284, Val Loss: 0.0799, Val MAE: 0.2096, Val RMSE: 0.2732\n",
      "New best validation loss: 0.0799 (previous best: 0.0985)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 20/100, Train Loss: 0.0987, Train MAE: 0.2395, Train RMSE: 0.3035, Val Loss: 0.0662, Val MAE: 0.1832, Val RMSE: 0.2447\n",
      "New best validation loss: 0.0662 (previous best: 0.0799)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 21/100, Train Loss: 0.1079, Train MAE: 0.2504, Train RMSE: 0.3173, Val Loss: 0.0813, Val MAE: 0.2130, Val RMSE: 0.2743\n",
      "No improvement, patience left: 9\n",
      "Epoch 22/100, Train Loss: 0.0775, Train MAE: 0.2094, Train RMSE: 0.2695, Val Loss: 0.0687, Val MAE: 0.1886, Val RMSE: 0.2524\n",
      "No improvement, patience left: 8\n",
      "Epoch 23/100, Train Loss: 0.0746, Train MAE: 0.2088, Train RMSE: 0.2647, Val Loss: 0.0657, Val MAE: 0.1777, Val RMSE: 0.2452\n",
      "New best validation loss: 0.0657 (previous best: 0.0662)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 24/100, Train Loss: 0.0766, Train MAE: 0.2113, Train RMSE: 0.2676, Val Loss: 0.0537, Val MAE: 0.1740, Val RMSE: 0.2248\n",
      "New best validation loss: 0.0537 (previous best: 0.0657)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 25/100, Train Loss: 0.0705, Train MAE: 0.2059, Train RMSE: 0.2579, Val Loss: 0.0651, Val MAE: 0.2008, Val RMSE: 0.2485\n",
      "No improvement, patience left: 9\n",
      "Epoch 26/100, Train Loss: 0.0648, Train MAE: 0.1957, Train RMSE: 0.2465, Val Loss: 0.0730, Val MAE: 0.2099, Val RMSE: 0.2630\n",
      "No improvement, patience left: 8\n",
      "Epoch 27/100, Train Loss: 0.0597, Train MAE: 0.1861, Train RMSE: 0.2357, Val Loss: 0.0478, Val MAE: 0.1534, Val RMSE: 0.2090\n",
      "New best validation loss: 0.0478 (previous best: 0.0537)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 28/100, Train Loss: 0.0490, Train MAE: 0.1712, Train RMSE: 0.2148, Val Loss: 0.0395, Val MAE: 0.1530, Val RMSE: 0.1925\n",
      "New best validation loss: 0.0395 (previous best: 0.0478)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 29/100, Train Loss: 0.0546, Train MAE: 0.1796, Train RMSE: 0.2252, Val Loss: 0.0777, Val MAE: 0.2072, Val RMSE: 0.2705\n",
      "No improvement, patience left: 9\n",
      "Epoch 30/100, Train Loss: 0.0541, Train MAE: 0.1816, Train RMSE: 0.2257, Val Loss: 0.0426, Val MAE: 0.1456, Val RMSE: 0.1970\n",
      "No improvement, patience left: 8\n",
      "Epoch 31/100, Train Loss: 0.0467, Train MAE: 0.1645, Train RMSE: 0.2079, Val Loss: 0.0383, Val MAE: 0.1332, Val RMSE: 0.1856\n",
      "New best validation loss: 0.0383 (previous best: 0.0395)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 32/100, Train Loss: 0.0423, Train MAE: 0.1579, Train RMSE: 0.1981, Val Loss: 0.0495, Val MAE: 0.1497, Val RMSE: 0.2118\n",
      "No improvement, patience left: 9\n",
      "Epoch 33/100, Train Loss: 0.0391, Train MAE: 0.1523, Train RMSE: 0.1910, Val Loss: 0.0291, Val MAE: 0.1173, Val RMSE: 0.1611\n",
      "New best validation loss: 0.0291 (previous best: 0.0383)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 34/100, Train Loss: 0.0391, Train MAE: 0.1506, Train RMSE: 0.1904, Val Loss: 0.0296, Val MAE: 0.1196, Val RMSE: 0.1629\n",
      "No improvement, patience left: 9\n",
      "Epoch 35/100, Train Loss: 0.0373, Train MAE: 0.1482, Train RMSE: 0.1845, Val Loss: 0.0330, Val MAE: 0.1336, Val RMSE: 0.1763\n",
      "No improvement, patience left: 8\n",
      "Epoch 36/100, Train Loss: 0.0386, Train MAE: 0.1518, Train RMSE: 0.1890, Val Loss: 0.0300, Val MAE: 0.1381, Val RMSE: 0.1701\n",
      "No improvement, patience left: 7\n",
      "Epoch 37/100, Train Loss: 0.0214, Train MAE: 0.1115, Train RMSE: 0.1428, Val Loss: 0.0186, Val MAE: 0.0993, Val RMSE: 0.1309\n",
      "New best validation loss: 0.0186 (previous best: 0.0291)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 38/100, Train Loss: 0.0199, Train MAE: 0.1078, Train RMSE: 0.1378, Val Loss: 0.0178, Val MAE: 0.0962, Val RMSE: 0.1282\n",
      "New best validation loss: 0.0178 (previous best: 0.0186)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 39/100, Train Loss: 0.0204, Train MAE: 0.1092, Train RMSE: 0.1392, Val Loss: 0.0186, Val MAE: 0.0996, Val RMSE: 0.1310\n",
      "No improvement, patience left: 9\n",
      "Epoch 40/100, Train Loss: 0.0204, Train MAE: 0.1098, Train RMSE: 0.1391, Val Loss: 0.0179, Val MAE: 0.0955, Val RMSE: 0.1283\n",
      "No improvement, patience left: 8\n",
      "Epoch 41/100, Train Loss: 0.0197, Train MAE: 0.1079, Train RMSE: 0.1359, Val Loss: 0.0188, Val MAE: 0.0998, Val RMSE: 0.1316\n",
      "No improvement, patience left: 7\n",
      "Epoch 42/100, Train Loss: 0.0172, Train MAE: 0.1006, Train RMSE: 0.1280, Val Loss: 0.0167, Val MAE: 0.0939, Val RMSE: 0.1240\n",
      "New best validation loss: 0.0167 (previous best: 0.0178)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 43/100, Train Loss: 0.0181, Train MAE: 0.1043, Train RMSE: 0.1311, Val Loss: 0.0163, Val MAE: 0.0902, Val RMSE: 0.1219\n",
      "New best validation loss: 0.0163 (previous best: 0.0167)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 44/100, Train Loss: 0.0168, Train MAE: 0.0995, Train RMSE: 0.1261, Val Loss: 0.0163, Val MAE: 0.0913, Val RMSE: 0.1218\n",
      "New best validation loss: 0.0163 (previous best: 0.0163)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 45/100, Train Loss: 0.0178, Train MAE: 0.1020, Train RMSE: 0.1295, Val Loss: 0.0162, Val MAE: 0.0908, Val RMSE: 0.1215\n",
      "New best validation loss: 0.0162 (previous best: 0.0163)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 46/100, Train Loss: 0.0170, Train MAE: 0.1023, Train RMSE: 0.1276, Val Loss: 0.0162, Val MAE: 0.0911, Val RMSE: 0.1216\n",
      "No improvement, patience left: 9\n",
      "Epoch 47/100, Train Loss: 0.0177, Train MAE: 0.1029, Train RMSE: 0.1298, Val Loss: 0.0159, Val MAE: 0.0903, Val RMSE: 0.1205\n",
      "New best validation loss: 0.0159 (previous best: 0.0162)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 48/100, Train Loss: 0.0170, Train MAE: 0.0999, Train RMSE: 0.1271, Val Loss: 0.0159, Val MAE: 0.0900, Val RMSE: 0.1205\n",
      "No improvement, patience left: 9\n",
      "Epoch 49/100, Train Loss: 0.0174, Train MAE: 0.1027, Train RMSE: 0.1284, Val Loss: 0.0159, Val MAE: 0.0895, Val RMSE: 0.1203\n",
      "No improvement, patience left: 8\n",
      "Epoch 50/100, Train Loss: 0.0171, Train MAE: 0.1002, Train RMSE: 0.1275, Val Loss: 0.0161, Val MAE: 0.0914, Val RMSE: 0.1212\n",
      "No improvement, patience left: 7\n",
      "Epoch 51/100, Train Loss: 0.0175, Train MAE: 0.1010, Train RMSE: 0.1280, Val Loss: 0.0159, Val MAE: 0.0899, Val RMSE: 0.1202\n",
      "New best validation loss: 0.0159 (previous best: 0.0159)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 52/100, Train Loss: 0.0170, Train MAE: 0.0998, Train RMSE: 0.1268, Val Loss: 0.0158, Val MAE: 0.0896, Val RMSE: 0.1201\n",
      "New best validation loss: 0.0158 (previous best: 0.0159)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 53/100, Train Loss: 0.0164, Train MAE: 0.0977, Train RMSE: 0.1246, Val Loss: 0.0159, Val MAE: 0.0896, Val RMSE: 0.1201\n",
      "No improvement, patience left: 9\n",
      "Epoch 54/100, Train Loss: 0.0179, Train MAE: 0.1026, Train RMSE: 0.1305, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1201\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 55/100, Train Loss: 0.0170, Train MAE: 0.1006, Train RMSE: 0.1275, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1201\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 56/100, Train Loss: 0.0166, Train MAE: 0.1002, Train RMSE: 0.1264, Val Loss: 0.0158, Val MAE: 0.0898, Val RMSE: 0.1201\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 57/100, Train Loss: 0.0175, Train MAE: 0.1005, Train RMSE: 0.1284, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1201\n",
      "No improvement, patience left: 9\n",
      "Epoch 58/100, Train Loss: 0.0172, Train MAE: 0.1012, Train RMSE: 0.1278, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1201\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 59/100, Train Loss: 0.0176, Train MAE: 0.1018, Train RMSE: 0.1295, Val Loss: 0.0158, Val MAE: 0.0896, Val RMSE: 0.1200\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 60/100, Train Loss: 0.0173, Train MAE: 0.1014, Train RMSE: 0.1283, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1200\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 61/100, Train Loss: 0.0178, Train MAE: 0.1003, Train RMSE: 0.1297, Val Loss: 0.0158, Val MAE: 0.0898, Val RMSE: 0.1200\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 62/100, Train Loss: 0.0172, Train MAE: 0.1013, Train RMSE: 0.1282, Val Loss: 0.0158, Val MAE: 0.0901, Val RMSE: 0.1201\n",
      "No improvement, patience left: 9\n",
      "Epoch 63/100, Train Loss: 0.0165, Train MAE: 0.0984, Train RMSE: 0.1250, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1199\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 64/100, Train Loss: 0.0171, Train MAE: 0.1005, Train RMSE: 0.1277, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1199\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 65/100, Train Loss: 0.0178, Train MAE: 0.1029, Train RMSE: 0.1296, Val Loss: 0.0158, Val MAE: 0.0896, Val RMSE: 0.1199\n",
      "No improvement, patience left: 9\n",
      "Epoch 66/100, Train Loss: 0.0166, Train MAE: 0.0996, Train RMSE: 0.1255, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 8\n",
      "Epoch 67/100, Train Loss: 0.0174, Train MAE: 0.1013, Train RMSE: 0.1286, Val Loss: 0.0158, Val MAE: 0.0897, Val RMSE: 0.1198\n",
      "New best validation loss: 0.0158 (previous best: 0.0158)\n",
      "Model checkpoint saved at best_cpg_model.pth\n",
      "Epoch 68/100, Train Loss: 0.0176, Train MAE: 0.1024, Train RMSE: 0.1298, Val Loss: 0.0158, Val MAE: 0.0894, Val RMSE: 0.1198\n",
      "No improvement, patience left: 9\n",
      "Epoch 69/100, Train Loss: 0.0168, Train MAE: 0.1010, Train RMSE: 0.1265, Val Loss: 0.0158, Val MAE: 0.0894, Val RMSE: 0.1198\n",
      "No improvement, patience left: 8\n",
      "Epoch 70/100, Train Loss: 0.0173, Train MAE: 0.1023, Train RMSE: 0.1291, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 7\n",
      "Epoch 71/100, Train Loss: 0.0168, Train MAE: 0.0998, Train RMSE: 0.1260, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 6\n",
      "Epoch 72/100, Train Loss: 0.0176, Train MAE: 0.1023, Train RMSE: 0.1294, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 5\n",
      "Epoch 73/100, Train Loss: 0.0178, Train MAE: 0.1032, Train RMSE: 0.1293, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 4\n",
      "Epoch 74/100, Train Loss: 0.0175, Train MAE: 0.1017, Train RMSE: 0.1285, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 3\n",
      "Epoch 75/100, Train Loss: 0.0160, Train MAE: 0.0985, Train RMSE: 0.1239, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 2\n",
      "Epoch 76/100, Train Loss: 0.0172, Train MAE: 0.0996, Train RMSE: 0.1274, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 1\n",
      "Epoch 77/100, Train Loss: 0.0179, Train MAE: 0.1022, Train RMSE: 0.1304, Val Loss: 0.0158, Val MAE: 0.0895, Val RMSE: 0.1198\n",
      "No improvement, patience left: 0\n",
      "Early Stopping Triggered after epoch 77\n",
      "Training Completed in 107.81 seconds\n",
      "Loaded checkpoint from best_cpg_model.pth, resuming from epoch 67 with best validation loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "best_model = train_model(\n",
    "    new_model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    epochs=num_epochs,\n",
    "    patience=stop_patience,\n",
    "    save_path=\"best_cpg_model.pth\",\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGGANNANAAATNNTGGANCTGNCTNNGTCGTNCGATANGTCNNATTTCNCTGGNANNNTGTGGTTTCCGGCGACNTGAGGATGGTCCGGCTCGNAGACNAANCGGGGNNCATGNGANCANNCNNANN\n",
      "7\n",
      "DNA: TGGANNANAAATNNTGGANCTGNCTNNGTCGTNCGATANGTCNNATTTCNCTGGNANNNTGTGGTTTCCGGCGACNTGAGGATGGTCCGGCTCGNAGACNAANCGGGGNNCATGNGANCANNCNNANN \n",
      "ðŸ”¹ Predicted CpG Count: 6.97\n"
     ]
    }
   ],
   "source": [
    "# Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "test_dna = test_x[91]\n",
    "test_dna = \"\".join(list(intseq_to_dnaseq(test_dna)))\n",
    "print(test_dna)\n",
    "print(count_cpgs(test_dna))\n",
    "\n",
    "# Predict the CpG count from the test DNA sequence\n",
    "predicted_cpgs = predict_cpgs_from_dna(\n",
    "    \"best_cpg_model.pth\",\n",
    "    test_dna,\n",
    "    dna2int,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounter,\n",
    ")\n",
    "\n",
    "print(f\"DNA: {test_dna} \\nðŸ”¹ Predicted CpG Count: {predicted_cpgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Advanced Concepts \n",
    "* New Model Architecture with Regularization and bilstm layer\n",
    "* Gradient Clipping\n",
    "* Mixed Precision Training and Gradient Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGCounterAdvanced(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialize the CpGCounterAdvanced model with an embedding layer, LSTM layer, batch normalization, and fully connected layer with ReLU activation.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size (int): Number of unique tokens in the vocabulary.\n",
    "        - embedding_dim (int): Dimension of the embedding layer.\n",
    "        - hidden_size (int): Dimension of the LSTM hidden state.\n",
    "        - num_layers (int): Number of LSTM layers.\n",
    "        - dropout (float): Dropout rate.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        super(CpGCounterAdvanced, self).__init__()\n",
    "        # Embedding layer to convert integer-encoded sequences to embeddings of fixed size (embedding_dim)\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, embedding_dim, padding_idx=0\n",
    "        )  # input: (batch_size, seq_len), output: (batch_size, seq_len, embedding_dim)\n",
    "        # LSTM layer to process the embeddings and capture sequential information (hidden_size) and bidirectional\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True,\n",
    "        )  # input: (batch_size, seq_len, embedding_dim), output: (batch_size, seq_len, hidden_size)\n",
    "        # add batch normalization 2 additional hidden states\n",
    "        self.batch_norm = nn.BatchNorm1d(\n",
    "            hidden_size * 2\n",
    "        )  # input: (batch_size, seq_len, hidden_size), output: (batch_size, seq_len, hidden_size)\n",
    "        # Fully connected layer to predict the number of CpG sites and ReLU activation\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_size * 2, 1\n",
    "        )  # input: (batch_size, seq_len, hidden_size), output: (batch_size, seq_len, 1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the CpGCounterAdvanced model with batch normalization and bidirectional LSTM.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            torch.max(x).item() < self.embedding.num_embeddings\n",
    "        ), \"Index out of range!\"\n",
    "        # Embed the input sequences\n",
    "        embedded = self.embedding(x)\n",
    "        # Process the embeddings with an LSTM layer\n",
    "        lstm_output, _ = self.lstm(embedded)\n",
    "        # we only take the last hidden state\n",
    "        lstm_output = lstm_output[\n",
    "            :, -1, :\n",
    "        ]  # shape is (batch_size, hidden_size) and we only take the last hidden state of the sequence\n",
    "        # Batch normalization\n",
    "        lstm_output = self.batch_norm(lstm_output)\n",
    "        # Predict the number of CpG sites\n",
    "        output = self.fc(lstm_output)\n",
    "        return self.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_advanced(\n",
    "    model, dataloader, device, optimizer, criterion, grad_scaler\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs one training epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to train.\n",
    "    - dataloader (DataLoader): Training DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "    - grad_scaler (GradScaler): Gradient scaler for mixed precision training.\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss (float): Average loss over dataset.\n",
    "    - avg_mae (float): Average MAE over dataset.\n",
    "    - avg_rmse (float): Average RMSE over dataset.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mae, total_rmse = 0.0, 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = (\n",
    "            inputs.to(device),\n",
    "            labels.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training context manager\n",
    "        with autocast(\"cuda\" if device.type == \"cuda\" else \"cpu\"):\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        # Compute batch-wise metrics\n",
    "        batch_mae = mean_absolute_error(\n",
    "            labels.cpu().numpy(), outputs.detach().cpu().numpy()\n",
    "        )\n",
    "        batch_rmse = (\n",
    "            mean_squared_error(labels.cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "            ** 0.5\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mae += batch_mae\n",
    "        total_rmse += batch_rmse\n",
    "\n",
    "    return total_loss / num_batches, total_mae / num_batches, total_rmse / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_advanced(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=25,\n",
    "    patience=5,\n",
    "    save_path=\"best_cpg_model_advanced.pth\",\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    resume=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model with validation and early stopping using mixed precision training. Supports resuming training.\n",
    "\n",
    "    Parameters:\n",
    "    - model: LSTM model.\n",
    "    - train_loader: Training DataLoader.\n",
    "    - val_loader: Validation DataLoader.\n",
    "    - device: CPU or GPU.\n",
    "    - epochs: Max training epochs.\n",
    "    - patience: Early stopping patience.\n",
    "    - save_path: Path to save the best model.\n",
    "    - lr: Initial learning rate.\n",
    "    - weight_decay: L2 regularization weight.\n",
    "    - resume: Whether to resume training from the last checkpoint.\n",
    "\n",
    "    Returns:\n",
    "    - Best trained model.\n",
    "    \"\"\"\n",
    "    # initialize model and optimizer and scheduler and criterion and best_val_loss and start_epoch\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "    )\n",
    "    # initialize gradient scaler\n",
    "    grad_scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if resuming\n",
    "    if resume and os.path.exists(save_path):\n",
    "        try:\n",
    "            model, optimizer, scheduler, start_epoch, best_val_loss = load_checkpoint(\n",
    "                model, optimizer, scheduler, device, save_path\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Starting training from scratch.\")\n",
    "\n",
    "    no_improvement = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            train_loss, train_mae, train_rmse = training_loop_advanced(\n",
    "                model, train_loader, device, optimizer, criterion, grad_scaler\n",
    "            )\n",
    "            val_loss, val_mae, val_rmse = validation_loop(\n",
    "                model, val_loader, device, criterion\n",
    "            )\n",
    "\n",
    "            # Scheduler step\n",
    "            if epoch > 0:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "            # Print results\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.4f}, Train RMSE: {train_rmse:.4f}, \"\n",
    "                f\"Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}, Val RMSE: {val_rmse:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Save best model checkpoint\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\n",
    "                    f\"New best validation loss: {val_loss:.4f} (previous best: {best_val_loss:.4f})\"\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "                save_checkpoint(\n",
    "                    epoch, model, optimizer, scheduler, best_val_loss, save_path\n",
    "                )\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                print(f\"No improvement, patience left: {patience - no_improvement}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if no_improvement >= patience:\n",
    "                print(f\"Early Stopping Triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training Interrupted! Saving last checkpoint...\")\n",
    "        save_checkpoint(epoch, model, optimizer, scheduler, best_val_loss, save_path)\n",
    "\n",
    "    print(f\"Training Completed in {(time.time() - start_time):.2f} seconds\")\n",
    "\n",
    "    # Load the best model before returning\n",
    "    model, optimizer, scheduler, _, _ = load_checkpoint(\n",
    "        model, optimizer, scheduler, device, save_path\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpGCounterAdvanced(\n",
      "  (embedding): Embedding(5, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize advanced model and check the model architecture\n",
    "advanced_model = CpGCounterAdvanced(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    ")\n",
    "print(advanced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 13.4829, Train MAE: 2.9420, Train RMSE: 3.6021, Val Loss: 9.5545, Val MAE: 2.3852, Val RMSE: 3.0410\n",
      "New best validation loss: 9.5545 (previous best: inf)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 2/100, Train Loss: 11.1175, Train MAE: 2.5958, Train RMSE: 3.2650, Val Loss: 9.3177, Val MAE: 2.3350, Val RMSE: 3.0000\n",
      "New best validation loss: 9.3177 (previous best: 9.5545)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 3/100, Train Loss: 10.8775, Train MAE: 2.5569, Train RMSE: 3.2281, Val Loss: 9.1568, Val MAE: 2.2986, Val RMSE: 2.9727\n",
      "New best validation loss: 9.1568 (previous best: 9.3177)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 4/100, Train Loss: 10.7779, Train MAE: 2.5348, Train RMSE: 3.2099, Val Loss: 9.2829, Val MAE: 2.3260, Val RMSE: 2.9935\n",
      "No improvement, patience left: 9\n",
      "Epoch 5/100, Train Loss: 10.5143, Train MAE: 2.4945, Train RMSE: 3.1700, Val Loss: 9.6358, Val MAE: 2.4362, Val RMSE: 3.0587\n",
      "No improvement, patience left: 8\n",
      "Epoch 6/100, Train Loss: 10.2006, Train MAE: 2.4363, Train RMSE: 3.1227, Val Loss: 8.6617, Val MAE: 2.2373, Val RMSE: 2.8897\n",
      "New best validation loss: 8.6617 (previous best: 9.1568)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 7/100, Train Loss: 7.2716, Train MAE: 1.8419, Train RMSE: 2.5595, Val Loss: 5.9767, Val MAE: 1.8835, Val RMSE: 2.4065\n",
      "New best validation loss: 5.9767 (previous best: 8.6617)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 8/100, Train Loss: 1.1813, Train MAE: 0.7543, Train RMSE: 0.9134, Val Loss: 1.1350, Val MAE: 0.8511, Val RMSE: 1.0530\n",
      "New best validation loss: 1.1350 (previous best: 5.9767)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 9/100, Train Loss: 0.4954, Train MAE: 0.5385, Train RMSE: 0.6507, Val Loss: 0.1593, Val MAE: 0.3095, Val RMSE: 0.3940\n",
      "New best validation loss: 0.1593 (previous best: 1.1350)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 10/100, Train Loss: 0.4501, Train MAE: 0.5116, Train RMSE: 0.6151, Val Loss: 0.0891, Val MAE: 0.2505, Val RMSE: 0.2947\n",
      "New best validation loss: 0.0891 (previous best: 0.1593)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 11/100, Train Loss: 0.4372, Train MAE: 0.5065, Train RMSE: 0.6002, Val Loss: 0.0985, Val MAE: 0.2554, Val RMSE: 0.3092\n",
      "No improvement, patience left: 9\n",
      "Epoch 12/100, Train Loss: 0.4196, Train MAE: 0.4986, Train RMSE: 0.5877, Val Loss: 0.0904, Val MAE: 0.2429, Val RMSE: 0.2965\n",
      "No improvement, patience left: 8\n",
      "Epoch 13/100, Train Loss: 0.3554, Train MAE: 0.4671, Train RMSE: 0.5423, Val Loss: 0.7278, Val MAE: 0.7542, Val RMSE: 0.8461\n",
      "No improvement, patience left: 7\n",
      "Epoch 14/100, Train Loss: 0.3181, Train MAE: 0.4437, Train RMSE: 0.5063, Val Loss: 0.0097, Val MAE: 0.0755, Val RMSE: 0.0966\n",
      "New best validation loss: 0.0097 (previous best: 0.0891)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 15/100, Train Loss: 0.2928, Train MAE: 0.4282, Train RMSE: 0.4885, Val Loss: 0.0098, Val MAE: 0.0778, Val RMSE: 0.0978\n",
      "No improvement, patience left: 9\n",
      "Epoch 16/100, Train Loss: 0.2830, Train MAE: 0.4240, Train RMSE: 0.4788, Val Loss: 0.0103, Val MAE: 0.0818, Val RMSE: 0.0999\n",
      "No improvement, patience left: 8\n",
      "Epoch 17/100, Train Loss: 0.2830, Train MAE: 0.4220, Train RMSE: 0.4781, Val Loss: 0.0082, Val MAE: 0.0701, Val RMSE: 0.0889\n",
      "New best validation loss: 0.0082 (previous best: 0.0097)\n",
      "Model checkpoint saved at best_cpg_model_advanced.pth\n",
      "Epoch 18/100, Train Loss: 0.2783, Train MAE: 0.4201, Train RMSE: 0.4750, Val Loss: 0.0153, Val MAE: 0.0947, Val RMSE: 0.1210\n",
      "No improvement, patience left: 9\n",
      "Epoch 19/100, Train Loss: 0.2781, Train MAE: 0.4198, Train RMSE: 0.4740, Val Loss: 0.0178, Val MAE: 0.1068, Val RMSE: 0.1315\n",
      "No improvement, patience left: 8\n",
      "Epoch 20/100, Train Loss: 0.2828, Train MAE: 0.4197, Train RMSE: 0.4757, Val Loss: 0.0197, Val MAE: 0.1153, Val RMSE: 0.1388\n",
      "No improvement, patience left: 7\n",
      "Epoch 21/100, Train Loss: 0.2651, Train MAE: 0.4123, Train RMSE: 0.4614, Val Loss: 0.0263, Val MAE: 0.1343, Val RMSE: 0.1603\n",
      "No improvement, patience left: 6\n",
      "Epoch 22/100, Train Loss: 0.2668, Train MAE: 0.4122, Train RMSE: 0.4636, Val Loss: 0.0292, Val MAE: 0.1426, Val RMSE: 0.1690\n",
      "No improvement, patience left: 5\n",
      "Epoch 23/100, Train Loss: 0.2660, Train MAE: 0.4130, Train RMSE: 0.4616, Val Loss: 0.0313, Val MAE: 0.1452, Val RMSE: 0.1747\n",
      "No improvement, patience left: 4\n",
      "Epoch 24/100, Train Loss: 0.2683, Train MAE: 0.4126, Train RMSE: 0.4636, Val Loss: 0.0334, Val MAE: 0.1506, Val RMSE: 0.1806\n",
      "No improvement, patience left: 3\n",
      "Epoch 25/100, Train Loss: 0.2664, Train MAE: 0.4116, Train RMSE: 0.4616, Val Loss: 0.0330, Val MAE: 0.1507, Val RMSE: 0.1796\n",
      "No improvement, patience left: 2\n",
      "Epoch 26/100, Train Loss: 0.2673, Train MAE: 0.4117, Train RMSE: 0.4632, Val Loss: 0.0312, Val MAE: 0.1457, Val RMSE: 0.1745\n",
      "No improvement, patience left: 1\n",
      "Epoch 27/100, Train Loss: 0.2669, Train MAE: 0.4114, Train RMSE: 0.4626, Val Loss: 0.0340, Val MAE: 0.1534, Val RMSE: 0.1823\n",
      "No improvement, patience left: 0\n",
      "Early Stopping Triggered after epoch 27\n",
      "Training Completed in 82.16 seconds\n",
      "Loaded checkpoint from best_cpg_model_advanced.pth, resuming from epoch 17 with best validation loss: 0.0082\n"
     ]
    }
   ],
   "source": [
    "best_model_advanced = train_model_advanced(\n",
    "    advanced_model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    epochs=num_epochs,\n",
    "    patience=stop_patience,\n",
    "    save_path=\"best_cpg_model_advanced.pth\",\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACAAGCTTGGGTATNGGCTACNNNGCGGCGCGCCTCTNTTTGCAGGTCNACACGACNTNAAGAANTAGNAAGGTNTGATAGTNCGNTGNACCGTACTCTATTNNNTNAGAGTCNAGTGCCTCNNCTNA\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "# ABS NEW Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "X_dna_seqs_train = list(rand_sequence(1))\n",
    "test_dna = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "y_dna_seqs = [count_cpgs(seq) for seq in test_dna]\n",
    "\n",
    "test_dna = test_dna[0]\n",
    "print(test_dna)\n",
    "print(y_dna_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA: ACAAGCTTGGGTATNGGCTACNNNGCGGCGCGCCTCTNTTTGCAGGTCNACACGACNTNAAGAANTAGNAAGGTNTGATAGTNCGNTGNACCGTACTCTATTNNNTNAGAGTCNAGTGCCTCNNCTNA \n",
      "ðŸ”¹ Predicted CpG Count: 5.96\n"
     ]
    }
   ],
   "source": [
    "# Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "# test_dna = test_x[19]\n",
    "# test_dna = \"\".join(list(intseq_to_dnaseq(test_dna)))\n",
    "# # print(test_dna)\n",
    "# print(count_cpgs(test_dna))\n",
    "\n",
    "# Predict the CpG count from the test DNA sequence\n",
    "predicted_cpgs = predict_cpgs_from_dna(\n",
    "    \"best_cpg_model_advanced.pth\",\n",
    "    test_dna,\n",
    "    dna2int,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounterAdvanced,\n",
    ")\n",
    "\n",
    "print(f\"DNA: {test_dna} \\nðŸ”¹ Predicted CpG Count: {predicted_cpgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways #####\n",
    "- The advanced model has a bidirectional LSTM layer and batch normalization layer to improve model performance.\n",
    "- The advanced model is trained using mixed precision training to speed up training and reduce memory usage.\n",
    "- The basic model reaches to the `val loss of 0.0158 at 67th epoch` whereas the advanced model reaches to the `val loss of 0.0082 at 17th epoch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMrRf_aVDRJm"
   },
   "source": [
    "# Part 2: what if the DNA sequences are not the same length\n",
    "- Here we try with the most conventional approach to handle variable length sequences using padding.\n",
    "- Padding has its own demerits like it increases the computation and memory usage and also the model may not learn the actual sequence pattern.\n",
    "- We can use the `PackedSequence` to handle variable length sequences which will be explained in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint we will need following imports\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AKvG-MNuXJr9"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE HERE\n",
    "random.seed(13)\n",
    "\n",
    "\n",
    "# Use this for getting x label\n",
    "def rand_sequence_var_len(n_seqs: int, lb: int = 16, ub: int = 128) -> Sequence[int]:\n",
    "    for i in range(n_seqs):\n",
    "        seq_len = random.randint(lb, ub)\n",
    "        yield [random.randint(1, 5) for _ in range(seq_len)]\n",
    "\n",
    "\n",
    "# Use this for getting y label\n",
    "def count_cpgs(seq: str) -> int:\n",
    "    cgs = 0\n",
    "    for i in range(0, len(seq) - 1):\n",
    "        dimer = seq[i : i + 2]\n",
    "        # note that seq is a string, not a list\n",
    "        if dimer == \"CG\":\n",
    "            cgs += 1\n",
    "    return cgs\n",
    "\n",
    "\n",
    "# Alphabet helpers\n",
    "alphabet = \"NACGT\"\n",
    "dna2int = {a: i for a, i in zip(alphabet, range(1, 6))}\n",
    "int2dna = {i: a for a, i in zip(alphabet, range(1, 6))}\n",
    "dna2int.update({\"pad\": 0})\n",
    "int2dna.update({0: \"<pad>\"})\n",
    "\n",
    "intseq_to_dnaseq = partial(map, int2dna.get)\n",
    "dnaseq_to_intseq = partial(map, dna2int.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N': 1, 'A': 2, 'C': 3, 'G': 4, 'T': 5, 'pad': 0}\n",
      "{1: 'N', 2: 'A', 3: 'C', 4: 'G', 5: 'T', 0: '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "print(dna2int)\n",
    "print(int2dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(dna2int)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(num_samples=100, min_len=16, max_len=128):\n",
    "    # TODO prepared the training and test data\n",
    "    # you need to call rand_sequence and count_cpgs here to create the dataset\n",
    "    # step 1\n",
    "    X_dna_seqs_train = list(rand_sequence_var_len(num_samples, min_len, max_len))\n",
    "    # step 2\n",
    "    temp = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "    # step3\n",
    "    y_dna_seqs = [count_cpgs(seq) for seq in temp]\n",
    "\n",
    "    return X_dna_seqs_train, y_dna_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len, max_len = 64, 128\n",
    "train_x, train_y = prepare_data(2048, min_len, max_len)\n",
    "test_x, test_y = prepare_data(512, min_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 64, 128, 64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(len, train_x)), min(map(len, train_x)), max(map(len, test_x)), min(map(len, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x[0], train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97]) torch.Size([])\n",
      "tensor([3, 2, 2, 2, 2, 2, 2, 1, 5, 2, 3, 1, 4, 2, 5, 1, 3, 2, 1, 3, 4, 4, 2, 3,\n",
      "        3, 2, 4, 5, 5, 4, 3, 4, 3, 1, 3, 5, 3, 4, 5, 5, 2, 4, 4, 5, 2, 3, 2, 2,\n",
      "        5, 3, 3, 3, 4, 3, 5, 3, 4, 2, 5, 4, 5, 2, 5, 2, 2, 3, 2, 1, 4, 4, 4, 1,\n",
      "        4, 1, 2, 2, 4, 4, 3, 2, 4, 3, 3, 2, 3, 5, 2, 5, 2, 4, 2, 5, 1, 5, 5, 1,\n",
      "        3]) tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# we will use the same pytorch dataset and dataloader classes\n",
    "\n",
    "# pytorch standard dataset\n",
    "train_dataset = CPGDataset(train_x, train_y)\n",
    "val_dataset = CPGDataset(test_x, test_y)\n",
    "\n",
    "# each iteration of the dataset will return a list of sequences and a labels\n",
    "x, y = next(iter(train_dataset))\n",
    "print(x.shape, y.shape)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch standard dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDataset.collate_fn,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 125]) torch.Size([16])\n",
      "torch.Size([16, 124]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n",
      "---\n",
      "torch.Size([16, 127]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n",
      "torch.Size([16, 128]) torch.Size([16])\n",
      "torch.Size([16, 126]) torch.Size([16])\n",
      "torch.Size([16, 125]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# this proves that the dataloader is working correctly we can batch the sequences of variable length\n",
    "i = 0\n",
    "for x_batch, y_batch in train_dataloader:\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break\n",
    "print(\"---\")\n",
    "i = 0\n",
    "for x_batch, y_batch in val_dataloader:\n",
    "    print(x_batch.shape, y_batch.shape)\n",
    "    i += 1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Note #####\n",
    "- Padding is done at the end of the sequence by the default padding value of 0 (which is the padding value for the integer-encoded sequences).\n",
    "- The padding is handled by the DataLoader collate_fn function, which pads the sequences to the maximum sequence length in the batch.\n",
    "- We will use the same advanced_model architecture with the CpGCounterAdvanced class for this task.\n",
    "- We will train the model using the train_model_advanced function, which supports mixed-precision training with gradient scaling.\n",
    "- We will train the model for 100 epochs with early stopping patience of 10 and save the best model checkpoint.\n",
    "- We will then evaluate the model on the test data and predict the CpG count for a random DNA sequence from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpGCounterAdvanced(\n",
      "  (embedding): Embedding(6, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize model and check the model architecture\n",
    "advanced_model_pad = CpGCounterAdvanced(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    ")\n",
    "print(advanced_model_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n",
      "Epoch 1/100, Train Loss: 8.2951, Train MAE: 2.2377, Train RMSE: 2.7856, Val Loss: 5.3890, Val MAE: 1.7540, Val RMSE: 2.3040\n",
      "New best validation loss: 5.3890 (previous best: inf)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 2/100, Train Loss: 5.2483, Train MAE: 1.7117, Train RMSE: 2.2594, Val Loss: 5.1635, Val MAE: 1.7253, Val RMSE: 2.2466\n",
      "New best validation loss: 5.1635 (previous best: 5.3890)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 3/100, Train Loss: 5.0814, Train MAE: 1.6900, Train RMSE: 2.2239, Val Loss: 5.6076, Val MAE: 1.7900, Val RMSE: 2.3327\n",
      "No improvement, patience left: 9\n",
      "Epoch 4/100, Train Loss: 4.9177, Train MAE: 1.6474, Train RMSE: 2.1865, Val Loss: 5.5442, Val MAE: 1.7724, Val RMSE: 2.3236\n",
      "No improvement, patience left: 8\n",
      "Epoch 5/100, Train Loss: 3.0757, Train MAE: 1.1039, Train RMSE: 1.6924, Val Loss: 2.5288, Val MAE: 0.8141, Val RMSE: 1.5242\n",
      "New best validation loss: 2.5288 (previous best: 5.1635)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 6/100, Train Loss: 2.5190, Train MAE: 0.8825, Train RMSE: 1.5230, Val Loss: 2.5245, Val MAE: 0.9014, Val RMSE: 1.5247\n",
      "New best validation loss: 2.5245 (previous best: 2.5288)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 7/100, Train Loss: 2.4496, Train MAE: 0.8489, Train RMSE: 1.4987, Val Loss: 2.3361, Val MAE: 0.8006, Val RMSE: 1.4554\n",
      "New best validation loss: 2.3361 (previous best: 2.5245)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 8/100, Train Loss: 2.4265, Train MAE: 0.8307, Train RMSE: 1.4914, Val Loss: 2.1432, Val MAE: 0.5540, Val RMSE: 1.3709\n",
      "New best validation loss: 2.1432 (previous best: 2.3361)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 9/100, Train Loss: 2.3853, Train MAE: 0.8129, Train RMSE: 1.4765, Val Loss: 2.0700, Val MAE: 0.5289, Val RMSE: 1.3538\n",
      "New best validation loss: 2.0700 (previous best: 2.1432)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 10/100, Train Loss: 2.3686, Train MAE: 0.8057, Train RMSE: 1.4721, Val Loss: 2.1601, Val MAE: 0.6175, Val RMSE: 1.3860\n",
      "No improvement, patience left: 9\n",
      "Epoch 11/100, Train Loss: 2.3479, Train MAE: 0.7922, Train RMSE: 1.4653, Val Loss: 2.3782, Val MAE: 0.9904, Val RMSE: 1.4861\n",
      "No improvement, patience left: 8\n",
      "Epoch 12/100, Train Loss: 2.3315, Train MAE: 0.7888, Train RMSE: 1.4590, Val Loss: 3.0658, Val MAE: 1.3858, Val RMSE: 1.7077\n",
      "No improvement, patience left: 7\n",
      "Epoch 13/100, Train Loss: 2.2034, Train MAE: 0.7152, Train RMSE: 1.4129, Val Loss: 1.9300, Val MAE: 0.6897, Val RMSE: 1.2882\n",
      "New best validation loss: 1.9300 (previous best: 2.0700)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 14/100, Train Loss: 2.1840, Train MAE: 0.7043, Train RMSE: 1.4061, Val Loss: 1.8890, Val MAE: 0.7475, Val RMSE: 1.2824\n",
      "New best validation loss: 1.8890 (previous best: 1.9300)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 15/100, Train Loss: 2.1582, Train MAE: 0.6966, Train RMSE: 1.3972, Val Loss: 1.7572, Val MAE: 0.6518, Val RMSE: 1.2164\n",
      "New best validation loss: 1.7572 (previous best: 1.8890)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 16/100, Train Loss: 2.1563, Train MAE: 0.6954, Train RMSE: 1.3975, Val Loss: 1.8501, Val MAE: 0.7564, Val RMSE: 1.2573\n",
      "No improvement, patience left: 9\n",
      "Epoch 17/100, Train Loss: 2.1475, Train MAE: 0.6917, Train RMSE: 1.3932, Val Loss: 1.9086, Val MAE: 0.7935, Val RMSE: 1.2868\n",
      "No improvement, patience left: 8\n",
      "Epoch 18/100, Train Loss: 2.1344, Train MAE: 0.6837, Train RMSE: 1.3875, Val Loss: 1.6928, Val MAE: 0.5972, Val RMSE: 1.1789\n",
      "New best validation loss: 1.6928 (previous best: 1.7572)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 19/100, Train Loss: 2.1362, Train MAE: 0.6812, Train RMSE: 1.3892, Val Loss: 1.7136, Val MAE: 0.6123, Val RMSE: 1.1927\n",
      "No improvement, patience left: 9\n",
      "Epoch 20/100, Train Loss: 2.1320, Train MAE: 0.6808, Train RMSE: 1.3869, Val Loss: 1.6823, Val MAE: 0.5821, Val RMSE: 1.1708\n",
      "New best validation loss: 1.6823 (previous best: 1.6928)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 21/100, Train Loss: 2.1304, Train MAE: 0.6785, Train RMSE: 1.3870, Val Loss: 1.7341, Val MAE: 0.6415, Val RMSE: 1.1976\n",
      "No improvement, patience left: 9\n",
      "Epoch 22/100, Train Loss: 2.1322, Train MAE: 0.6810, Train RMSE: 1.3867, Val Loss: 1.6995, Val MAE: 0.6164, Val RMSE: 1.1845\n",
      "No improvement, patience left: 8\n",
      "Epoch 23/100, Train Loss: 2.1311, Train MAE: 0.6786, Train RMSE: 1.3867, Val Loss: 1.7687, Val MAE: 0.6903, Val RMSE: 1.2193\n",
      "No improvement, patience left: 7\n",
      "Epoch 24/100, Train Loss: 2.1250, Train MAE: 0.6758, Train RMSE: 1.3843, Val Loss: 1.6091, Val MAE: 0.4912, Val RMSE: 1.1320\n",
      "New best validation loss: 1.6091 (previous best: 1.6823)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 25/100, Train Loss: 2.1250, Train MAE: 0.6750, Train RMSE: 1.3845, Val Loss: 1.6046, Val MAE: 0.4838, Val RMSE: 1.1293\n",
      "New best validation loss: 1.6046 (previous best: 1.6091)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 26/100, Train Loss: 2.1218, Train MAE: 0.6714, Train RMSE: 1.3829, Val Loss: 1.6144, Val MAE: 0.5011, Val RMSE: 1.1345\n",
      "No improvement, patience left: 9\n",
      "Epoch 27/100, Train Loss: 2.1219, Train MAE: 0.6709, Train RMSE: 1.3832, Val Loss: 1.6171, Val MAE: 0.5030, Val RMSE: 1.1377\n",
      "No improvement, patience left: 8\n",
      "Epoch 28/100, Train Loss: 2.1207, Train MAE: 0.6711, Train RMSE: 1.3819, Val Loss: 1.6104, Val MAE: 0.4926, Val RMSE: 1.1338\n",
      "No improvement, patience left: 7\n",
      "Epoch 29/100, Train Loss: 2.1247, Train MAE: 0.6762, Train RMSE: 1.3845, Val Loss: 1.6076, Val MAE: 0.4873, Val RMSE: 1.1329\n",
      "No improvement, patience left: 6\n",
      "Epoch 30/100, Train Loss: 2.1175, Train MAE: 0.6686, Train RMSE: 1.3812, Val Loss: 1.6039, Val MAE: 0.4807, Val RMSE: 1.1321\n",
      "New best validation loss: 1.6039 (previous best: 1.6046)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 31/100, Train Loss: 2.1226, Train MAE: 0.6725, Train RMSE: 1.3837, Val Loss: 1.6053, Val MAE: 0.4811, Val RMSE: 1.1334\n",
      "No improvement, patience left: 9\n",
      "Epoch 32/100, Train Loss: 2.1184, Train MAE: 0.6703, Train RMSE: 1.3810, Val Loss: 1.6046, Val MAE: 0.4835, Val RMSE: 1.1308\n",
      "No improvement, patience left: 8\n",
      "Epoch 33/100, Train Loss: 2.1213, Train MAE: 0.6724, Train RMSE: 1.3826, Val Loss: 1.6030, Val MAE: 0.4818, Val RMSE: 1.1309\n",
      "New best validation loss: 1.6030 (previous best: 1.6039)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 34/100, Train Loss: 2.1203, Train MAE: 0.6707, Train RMSE: 1.3829, Val Loss: 1.6101, Val MAE: 0.4917, Val RMSE: 1.1348\n",
      "No improvement, patience left: 9\n",
      "Epoch 35/100, Train Loss: 2.1215, Train MAE: 0.6730, Train RMSE: 1.3828, Val Loss: 1.6044, Val MAE: 0.4868, Val RMSE: 1.1294\n",
      "No improvement, patience left: 8\n",
      "Epoch 36/100, Train Loss: 2.1243, Train MAE: 0.6741, Train RMSE: 1.3842, Val Loss: 1.6062, Val MAE: 0.4846, Val RMSE: 1.1337\n",
      "No improvement, patience left: 7\n",
      "Epoch 37/100, Train Loss: 2.1193, Train MAE: 0.6702, Train RMSE: 1.3817, Val Loss: 1.6037, Val MAE: 0.4839, Val RMSE: 1.1289\n",
      "No improvement, patience left: 6\n",
      "Epoch 38/100, Train Loss: 2.1218, Train MAE: 0.6714, Train RMSE: 1.3833, Val Loss: 1.6060, Val MAE: 0.4840, Val RMSE: 1.1336\n",
      "No improvement, patience left: 5\n",
      "Epoch 39/100, Train Loss: 2.1195, Train MAE: 0.6687, Train RMSE: 1.3816, Val Loss: 1.6024, Val MAE: 0.4813, Val RMSE: 1.1310\n",
      "New best validation loss: 1.6024 (previous best: 1.6030)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 40/100, Train Loss: 2.1179, Train MAE: 0.6690, Train RMSE: 1.3815, Val Loss: 1.6058, Val MAE: 0.4854, Val RMSE: 1.1312\n",
      "No improvement, patience left: 9\n",
      "Epoch 41/100, Train Loss: 2.1236, Train MAE: 0.6736, Train RMSE: 1.3840, Val Loss: 1.6022, Val MAE: 0.4804, Val RMSE: 1.1293\n",
      "New best validation loss: 1.6022 (previous best: 1.6024)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 42/100, Train Loss: 2.1224, Train MAE: 0.6729, Train RMSE: 1.3832, Val Loss: 1.6068, Val MAE: 0.4891, Val RMSE: 1.1314\n",
      "No improvement, patience left: 9\n",
      "Epoch 43/100, Train Loss: 2.1207, Train MAE: 0.6704, Train RMSE: 1.3829, Val Loss: 1.6015, Val MAE: 0.4779, Val RMSE: 1.1305\n",
      "New best validation loss: 1.6015 (previous best: 1.6022)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 44/100, Train Loss: 2.1221, Train MAE: 0.6703, Train RMSE: 1.3829, Val Loss: 1.6008, Val MAE: 0.4808, Val RMSE: 1.1286\n",
      "New best validation loss: 1.6008 (previous best: 1.6015)\n",
      "Model checkpoint saved at best_cpg_model_advanced_pad.pth\n",
      "Epoch 45/100, Train Loss: 2.1175, Train MAE: 0.6687, Train RMSE: 1.3812, Val Loss: 1.6028, Val MAE: 0.4837, Val RMSE: 1.1286\n",
      "No improvement, patience left: 9\n",
      "Epoch 46/100, Train Loss: 2.1233, Train MAE: 0.6739, Train RMSE: 1.3841, Val Loss: 1.6033, Val MAE: 0.4845, Val RMSE: 1.1286\n",
      "No improvement, patience left: 8\n",
      "Epoch 47/100, Train Loss: 2.1212, Train MAE: 0.6719, Train RMSE: 1.3828, Val Loss: 1.6023, Val MAE: 0.4791, Val RMSE: 1.1301\n",
      "No improvement, patience left: 7\n",
      "Epoch 48/100, Train Loss: 2.1214, Train MAE: 0.6736, Train RMSE: 1.3824, Val Loss: 1.6047, Val MAE: 0.4826, Val RMSE: 1.1315\n",
      "No improvement, patience left: 6\n",
      "Epoch 49/100, Train Loss: 2.1186, Train MAE: 0.6704, Train RMSE: 1.3820, Val Loss: 1.6027, Val MAE: 0.4813, Val RMSE: 1.1300\n",
      "No improvement, patience left: 5\n",
      "Epoch 50/100, Train Loss: 2.1194, Train MAE: 0.6706, Train RMSE: 1.3818, Val Loss: 1.6029, Val MAE: 0.4821, Val RMSE: 1.1298\n",
      "No improvement, patience left: 4\n",
      "Epoch 51/100, Train Loss: 2.1231, Train MAE: 0.6745, Train RMSE: 1.3841, Val Loss: 1.6082, Val MAE: 0.4877, Val RMSE: 1.1346\n",
      "No improvement, patience left: 3\n",
      "Epoch 52/100, Train Loss: 2.1173, Train MAE: 0.6687, Train RMSE: 1.3810, Val Loss: 1.6065, Val MAE: 0.4893, Val RMSE: 1.1299\n",
      "No improvement, patience left: 2\n",
      "Epoch 53/100, Train Loss: 2.1217, Train MAE: 0.6729, Train RMSE: 1.3830, Val Loss: 1.6063, Val MAE: 0.4854, Val RMSE: 1.1315\n",
      "No improvement, patience left: 1\n",
      "Epoch 54/100, Train Loss: 2.1229, Train MAE: 0.6731, Train RMSE: 1.3833, Val Loss: 1.6052, Val MAE: 0.4887, Val RMSE: 1.1292\n",
      "No improvement, patience left: 0\n",
      "Early Stopping Triggered after epoch 54\n",
      "Training Completed in 164.44 seconds\n",
      "Loaded checkpoint from best_cpg_model_advanced_pad.pth, resuming from epoch 44 with best validation loss: 1.6008\n"
     ]
    }
   ],
   "source": [
    "best_model_advanced_pad = train_model_advanced(\n",
    "    advanced_model_pad,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    epochs=num_epochs,\n",
    "    patience=stop_patience,\n",
    "    save_path=\"best_cpg_model_advanced_pad.pth\",\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the above output you see a stagnating improvement in the validation loss and this is due to padding. The model is learning to ignore the padding tokens and this is causing the model to not learn the correct patterns. This is a common issue with padding and variable length sequences. One way to solve this is to use pack_padded_sequence and pad_packed_sequence to handle variable length sequences. This will be covered in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGNAATATACGAAATCTTNAAANGNNGAATGANTANGCNAGTNTCCGNGCTGCANAGGGANTN\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# ABS NEW Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "X_dna_seqs_train = list(rand_sequence_var_len(1, min_len, max_len))\n",
    "test_dna = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "y_dna_seqs = [count_cpgs(seq) for seq in test_dna]\n",
    "\n",
    "test_dna = test_dna[0]\n",
    "print(test_dna)\n",
    "print(y_dna_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNA: ANGNAATATACGAAATCTTNAAANGNNGAATGANTANGCNAGTNTCCGNGCTGCANAGGGANTN \n",
      "ðŸ”¹ Predicted CpG Count: 0.0\n"
     ]
    }
   ],
   "source": [
    "# test prediction from the advanced model\n",
    "predicted_cpgs = predict_cpgs_from_dna(\n",
    "    \"best_cpg_model_advanced_pad.pth\",\n",
    "    test_dna,\n",
    "    dna2int,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounterAdvanced,\n",
    ")\n",
    "\n",
    "print(f\"DNA: {test_dna} \\nðŸ”¹ Predicted CpG Count: {predicted_cpgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Padding and Packing Sequences for RNNs in PyTorch\n",
    "\n",
    "- Sort sequences by length (longest first).\n",
    "- Pack sequences using torch.nn.utils.rnn.pack_padded_sequence.\n",
    "- LSTM skips padded timesteps, processing only actual data.\n",
    "- Unpack the sequences back using pad_packed_sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPGDatasetPackPadding(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with sequences and labels (CpG counts) as input arguments and store them as attributes.\n",
    "\n",
    "        Parameters:\n",
    "        - sequences (List[List[int]]): List of integer-encoded DNA sequences.\n",
    "        - labels (List[int]): List of CpG counts corresponding to each sequence.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.sequences = [torch.tensor(seq, dtype=torch.long) for seq in sequences]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of sequences in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a sequence and its label by index.\n",
    "        \"\"\"\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"\n",
    "        Custom collate function to pack sequences dynamically and return a batch of sequences and labels with lengths.\n",
    "        \"\"\"\n",
    "        sequences, labels = zip(*batch)\n",
    "        # find the lenghts of the sequences and sort them\n",
    "        lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "        sorted_indices = torch.argsort(lengths, descending=True)\n",
    "        # sort sequences by length\n",
    "        sequences = [sequences[i] for i in sorted_indices]\n",
    "        # sort labels by length\n",
    "        labels = torch.tensor([labels[i] for i in sorted_indices], dtype=torch.float32)\n",
    "        lengths = lengths[sorted_indices]\n",
    "\n",
    "        # pad sequences and return a packed sequence and labels and lengths\n",
    "        pad_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "        return pad_sequences, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# pytorch standard dataset\n",
    "train_dataset = CPGDatasetPackPadding(train_x, train_y)\n",
    "val_dataset = CPGDatasetPackPadding(test_x, test_y)\n",
    "\n",
    "# each iteration of the dataset will return a list of sequences and a labels\n",
    "x, y = next(iter(train_dataset))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 125]) torch.Size([16]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# standard dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDatasetPackPadding.collate_fn,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=CPGDatasetPackPadding.collate_fn,\n",
    ")\n",
    "\n",
    "# each iteration of the dataloader will return a batch of sequences and labels\n",
    "for x_batch, y_batch, lengths in train_dataloader:\n",
    "    print(x_batch.shape, y_batch.shape, lengths.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CpGCounterAdvancedPackPadding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        \"\"\"\n",
    "        Initialize the CpGCounterAdvancedPackPadding model with an embedding layer, LSTM layer, batch normalization, and fully connected layer with ReLU activation.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size (int): Number of unique tokens in the vocabulary.\n",
    "        - embedding_dim (int): Dimension of the embedding layer.\n",
    "        - hidden_size (int): Dimension of the LSTM hidden state.\n",
    "        - num_layers (int): Number of LSTM layers.\n",
    "        - dropout (float): Dropout rate.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        \n",
    "        super(CpGCounterAdvancedPackPadding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass using packed sequences to handle variable length sequences.\n",
    "\n",
    "        Parameters:\n",
    "        - x: (batch_size, seq_len) -> Padded sequences.\n",
    "        - lengths: (batch_size) -> Actual sequence lengths.\n",
    "\n",
    "        Returns:\n",
    "        - CpG count prediction.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            torch.max(x).item() < self.embedding.num_embeddings\n",
    "        ), \"Index out of range!\"\n",
    "        embedded = self.embedding(\n",
    "            x\n",
    "        )  # input: (batch_size, seq_len), output: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # Pack sequence to ignore padding\n",
    "        packed_embedded = pack_padded_sequence(\n",
    "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=True\n",
    "        )\n",
    "\n",
    "        # LSTM processing\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "\n",
    "        # Unpack sequence to get the output of each time step (hidden states)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        # Extract last valid hidden state dynamically (from both directions)\n",
    "        batch_indices = torch.arange(x.size(0), device=x.device)\n",
    "        last_indices = lengths - 1\n",
    "        last_hidden_states = output[batch_indices, last_indices, :]\n",
    "\n",
    "        # Apply batch norm & fully connected layer\n",
    "        last_hidden_states = self.batch_norm(last_hidden_states)\n",
    "        output = self.fc(last_hidden_states)\n",
    "        return self.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_pack_padded(\n",
    "    model, dataloader, device, optimizer, criterion, grad_scaler\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs one training epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to train.\n",
    "    - dataloader (DataLoader): Training DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "    - grad_scaler (GradScaler): Gradient scaler for mixed precision training.\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss (float): Average loss over dataset.\n",
    "    - avg_mae (float): Average MAE over dataset.\n",
    "    - avg_rmse (float): Average RMSE over dataset.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_mae, total_rmse = 0.0, 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for inputs, labels, lengths in dataloader:\n",
    "        inputs, labels, lengths = (\n",
    "            inputs.to(device),\n",
    "            labels.to(device),\n",
    "            lengths.to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(\"cuda\" if device.type == \"cuda\" else \"cpu\"):\n",
    "            outputs = model(inputs, lengths).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        # Compute batch-wise metrics\n",
    "        batch_mae = mean_absolute_error(\n",
    "            labels.cpu().numpy(), outputs.detach().cpu().numpy()\n",
    "        )\n",
    "        batch_rmse = (\n",
    "            mean_squared_error(labels.cpu().numpy(), outputs.detach().cpu().numpy())\n",
    "            ** 0.5\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_mae += batch_mae\n",
    "        total_rmse += batch_rmse\n",
    "\n",
    "    return total_loss / num_batches, total_mae / num_batches, total_rmse / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop_pack_padded(model, dataloader, device, criterion):\n",
    "    \"\"\"\n",
    "    Runs one validation epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to evaluate.\n",
    "    - dataloader (DataLoader): Validation DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "\n",
    "    Returns:\n",
    "    - avg_loss (float): Average loss over dataset.\n",
    "    - avg_mae (float): Average MAE over dataset.\n",
    "    - avg_rmse (float): Average RMSE over dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_mae, total_rmse = 0.0, 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in dataloader:\n",
    "            inputs, labels, lengths = (\n",
    "                inputs.to(device),\n",
    "                labels.to(device),\n",
    "                lengths.to(device),\n",
    "            )\n",
    "            outputs = model(inputs, lengths).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute batch-wise metrics\n",
    "            batch_mae = mean_absolute_error(labels.cpu().numpy(), outputs.cpu().numpy())\n",
    "            batch_rmse = (\n",
    "                mean_squared_error(labels.cpu().numpy(), outputs.cpu().numpy()) ** 0.5\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_mae += batch_mae\n",
    "            total_rmse += batch_rmse\n",
    "\n",
    "    return total_loss / num_batches, total_mae / num_batches, total_rmse / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_pack_padded(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    epochs=25,\n",
    "    patience=5,\n",
    "    save_path=\"best_cpg_model_advanced.pth\",\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4,\n",
    "    resume=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains an LSTM model with validation and early stopping. Supports resuming training.\n",
    "\n",
    "    Parameters:\n",
    "    - model: LSTM model.\n",
    "    - train_loader: Training DataLoader.\n",
    "    - val_loader: Validation DataLoader.\n",
    "    - device: CPU or GPU.\n",
    "    - epochs: Max training epochs.\n",
    "    - patience: Early stopping patience.\n",
    "    - save_path: Path to save the best model.\n",
    "    - lr: Initial learning rate.\n",
    "    - weight_decay: L2 regularization weight.\n",
    "    - resume: Whether to resume training from the last checkpoint.\n",
    "\n",
    "    Returns:\n",
    "    - Best trained model.\n",
    "    \"\"\"\n",
    "    # initialize model and optimizer and scheduler and criterion and best_val_loss and start_epoch\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=0.1,\n",
    "        patience=2,\n",
    "    )\n",
    "    # initialize gradient scaler\n",
    "    grad_scaler = GradScaler()\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Load checkpoint if resuming\n",
    "    if resume and os.path.exists(save_path):\n",
    "        try:\n",
    "            model, optimizer, scheduler, start_epoch, best_val_loss = load_checkpoint(\n",
    "                model, optimizer, scheduler, device, save_path\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Starting training from scratch.\")\n",
    "\n",
    "    no_improvement = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            train_loss, train_mae, train_rmse = training_loop_pack_padded(\n",
    "                model, train_loader, device, optimizer, criterion, grad_scaler\n",
    "            )\n",
    "            val_loss, val_mae, val_rmse = validation_loop_pack_padded(\n",
    "                model, val_loader, device, criterion\n",
    "            )\n",
    "\n",
    "            # Scheduler step\n",
    "            if epoch > 0:\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "            # Print results\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.4f}, Train RMSE: {train_rmse:.4f}, \"\n",
    "                f\"Val Loss: {val_loss:.4f}, Val MAE: {val_mae:.4f}, Val RMSE: {val_rmse:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Save best model checkpoint\n",
    "            if val_loss < best_val_loss:\n",
    "                print(\n",
    "                    f\"New best validation loss: {val_loss:.4f} (previous best: {best_val_loss:.4f})\"\n",
    "                )\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "                save_checkpoint(\n",
    "                    epoch, model, optimizer, scheduler, best_val_loss, save_path\n",
    "                )\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                print(f\"No improvement, patience left: {patience - no_improvement}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if no_improvement >= patience:\n",
    "                print(f\"Early Stopping Triggered after epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training Interrupted! Saving last checkpoint...\")\n",
    "        save_checkpoint(epoch, model, optimizer, scheduler, best_val_loss, save_path)\n",
    "\n",
    "    print(f\"Training Completed in {(time.time() - start_time):.2f} seconds\")\n",
    "\n",
    "    # Load the best model before returning\n",
    "    model, optimizer, scheduler, _, _ = load_checkpoint(\n",
    "        model, optimizer, scheduler, device, save_path\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cpgs_from_dna_pack_padded(\n",
    "    model_path: str,\n",
    "    dna_sequence: str,\n",
    "    dna2int: dict,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounterAdvanced,  # Ensure the correct model class is used\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict CpG count from a human DNA string.\n",
    "\n",
    "    Parameters:\n",
    "    - model_path: Path to trained LSTM model.\n",
    "    - dna_sequence: Human-readable DNA string.\n",
    "    - dna2int: Dictionary mapping DNA bases to integer values.\n",
    "    - embedding_dim: Dimension of embedding layer.\n",
    "    - hidden_size: Size of LSTM hidden state.\n",
    "    - num_layers: Number of LSTM layers.\n",
    "    - dropout: Dropout rate.\n",
    "    - device: The device ('cpu' or 'cuda') for inference.\n",
    "    - model_class: The model class to initialize the architecture.\n",
    "\n",
    "    Returns:\n",
    "    - Predicted CpG count (rounded to 2 decimal places).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the model checkpoint exists\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {model_path}\")\n",
    "\n",
    "    # Load Model\n",
    "    vocab_size = len(dna2int)\n",
    "    model = model_class(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    )\n",
    "\n",
    "    # Load the trained model checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)  # Move model to the correct device\n",
    "    model.eval()\n",
    "\n",
    "    # Convert DNA string to integer sequence\n",
    "    int_sequence = [\n",
    "        dna2int.get(base, 0) for base in dna_sequence\n",
    "    ]  # Map bases to integers\n",
    "    int_tensor = (\n",
    "        torch.tensor(int_sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    )  # Add batch dim\n",
    "\n",
    "    # Compute sequence length (as tensor) and move to the same device\n",
    "    lengths = torch.tensor([len(int_sequence)], dtype=torch.long).to(device)\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        predicted_count = (\n",
    "            model(int_tensor, lengths).squeeze().item()\n",
    "        )  # Ensure it's a scalar\n",
    "\n",
    "    return round(predicted_count, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CpGCounterAdvancedPackPadding(\n",
      "  (embedding): Embedding(6, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = CpGCounterAdvancedPackPadding(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    ")\n",
    "\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model_pack_padded(\n",
    "    new_model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    epochs=num_epochs,\n",
    "    patience=stop_patience,\n",
    "    save_path=\"best_cpg_model_advanced_packpad.pth\",\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Takeaways #####\n",
    "- Padding is a common technique used to handle variable-length sequences in PyTorch.\n",
    "- Padding can lead to inefficiencies and model performance issues as a result we see a stagnating `validation loss of around 1.60`\n",
    "- We have used the pack_padded_sequence and pad_packed_sequence functions to handle variable-length sequences which has shown a significant improvement in model performance resulting in a `validation loss of around 0.0166`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNTGNAACCNGCANTNNAGGTGAATNCTGTCAGNCCNCNGTANTCNCTGCTCATAGNANAAATNCNACGCAGGTCATATATGTTATNTCNCGGACGGANTG\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# ABS NEW Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "X_dna_seqs_train = list(rand_sequence_var_len(1, min_len, max_len))\n",
    "test_dna = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "y_dna_seqs = [count_cpgs(seq) for seq in test_dna]\n",
    "\n",
    "test_dna = test_dna[0]\n",
    "print(test_dna)\n",
    "print(y_dna_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction from the advanced model\n",
    "predicted_cpgs = predict_cpgs_from_dna_pack_padded(\n",
    "    \"best_cpg_model_advanced_packpad.pth\",\n",
    "    test_dna,\n",
    "    dna2int,\n",
    "    embedding_dim,\n",
    "    hidden_size,\n",
    "    num_layers,\n",
    "    dropout,\n",
    "    device,\n",
    "    model_class=CpGCounterAdvancedPackPadding,\n",
    ")\n",
    "print(\"Voila! The model is working perfectly\")\n",
    "print(f\"DNA: {test_dna} \\nðŸ”¹ Predicted CpG Count: {predicted_cpgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next we will try implementing OPtuna for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna hyperparameter optimization.\n",
    "\n",
    "    Parameters:\n",
    "    - trial: Optuna trial object.\n",
    "\n",
    "    Returns:\n",
    "    - Best validation loss for the trial.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample hyperparameters\n",
    "    embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [128, 256, 512])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2)\n",
    "    dropout = trial.suggest_uniform(\"dropout\", 0.1, 0.25)\n",
    "\n",
    "    # Initialize the model and also optimizer, criterion, scheduler, and gradient scaler\n",
    "    model = CpGCounterAdvancedPackPadding(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=embedding_dim,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2)\n",
    "    grad_scaler = GradScaler()\n",
    "\n",
    "    # Training parameters\n",
    "    num_epochs = 20\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, _, _ = training_loop_pack_padded(\n",
    "            model, train_dataloader, device, optimizer, criterion, grad_scaler\n",
    "        )\n",
    "        val_loss, _, _ = validation_loop_pack_padded(\n",
    "            model, val_dataloader, device, criterion\n",
    "        )\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna Study for Hyperparameter Optimization\n",
    "def tune_hyperparameters(\n",
    "    vocab_size,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    stop_patience,\n",
    "    n_trials=10,\n",
    "    save_best_model_path=\"best_cpg_model_optuna.pth\",\n",
    "    study_name=\"cpg_optuna\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs Optuna hyperparameter tuning and trains the best model.\n",
    "\n",
    "    Parameters:\n",
    "    - vocab_size (int): Number of unique tokens in the vocabulary.\n",
    "    - train_dataloader (DataLoader): Training DataLoader.\n",
    "    - val_dataloader (DataLoader): Validation DataLoader.\n",
    "    - device (torch.device): CPU or GPU.\n",
    "    - num_epochs (int): Max training epochs.\n",
    "    - stop_patience (int): Early stopping patience.\n",
    "    - n_trials (int): Number of Optuna trials.\n",
    "    - save_best_model_path (str): Path to save the best model.\n",
    "    - study_name (str): Name of the Optuna study.\n",
    "\n",
    "    Returns:\n",
    "    - Best hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        study_name=study_name,\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "    )\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "    # Train model with best hyperparameters\n",
    "    best_model = CpGCounterAdvancedPackPadding(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=best_params[\"embedding_dim\"],\n",
    "        hidden_size=best_params[\"hidden_size\"],\n",
    "        num_layers=best_params[\"num_layers\"],\n",
    "        dropout=best_params[\"dropout\"],\n",
    "    ).to(device)\n",
    "\n",
    "    trained_model = train_model_pack_padded(\n",
    "        best_model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        device,\n",
    "        epochs=num_epochs,\n",
    "        patience=stop_patience,\n",
    "        save_path=save_best_model_path,\n",
    "        lr=best_params[\"learning_rate\"],\n",
    "        weight_decay=best_params[\"weight_decay\"],\n",
    "    )\n",
    "\n",
    "    return best_params, trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-02-03 12:55:13,676]\u001b[0m A new study created in memory with name: cpg_optuna\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 12:56:53,029]\u001b[0m Trial 0 finished with value: 3.900638170540333 and parameters: {'embedding_dim': 64, 'hidden_size': 256, 'num_layers': 3, 'learning_rate': 0.008960479682872323, 'weight_decay': 5.064009043928203e-06, 'dropout': 0.10941602924918034}. Best is trial 0 with value: 3.900638170540333.\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 12:58:28,121]\u001b[0m Trial 1 finished with value: 0.02458490733988583 and parameters: {'embedding_dim': 64, 'hidden_size': 128, 'num_layers': 3, 'learning_rate': 0.0034322916006087082, 'weight_decay': 2.017936813234936e-06, 'dropout': 0.24262490555931504}. Best is trial 1 with value: 0.02458490733988583.\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 12:59:39,929]\u001b[0m Trial 2 finished with value: 0.015624458756064996 and parameters: {'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.001390966656576865, 'weight_decay': 0.0005749676565299976, 'dropout': 0.16242847730398327}. Best is trial 2 with value: 0.015624458756064996.\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 13:01:41,877]\u001b[0m Trial 3 finished with value: 0.019784464995609596 and parameters: {'embedding_dim': 256, 'hidden_size': 512, 'num_layers': 3, 'learning_rate': 0.0018325114649661936, 'weight_decay': 1.865579607829215e-05, 'dropout': 0.11594965293232022}. Best is trial 2 with value: 0.015624458756064996.\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 13:03:17,003]\u001b[0m Trial 4 finished with value: 0.025330739532364532 and parameters: {'embedding_dim': 256, 'hidden_size': 128, 'num_layers': 3, 'learning_rate': 0.002254292851670547, 'weight_decay': 0.00037095688454756646, 'dropout': 0.15691790409079256}. Best is trial 2 with value: 0.015624458756064996.\u001b[0m\n",
      "\u001b[32m[I 2025-02-03 13:03:21,764]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-02-03 13:03:25,382]\u001b[0m Trial 6 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'learning_rate': 0.001390966656576865, 'weight_decay': 0.0005749676565299976, 'dropout': 0.16242847730398327}\n",
      "Starting training from scratch.\n",
      "Epoch 1/100, Train Loss: 9.6349, Train MAE: 2.4910, Train RMSE: 3.0494, Val Loss: 6.0860, Val MAE: 1.9293, Val RMSE: 2.4262\n",
      "New best validation loss: 6.0860 (previous best: inf)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 2/100, Train Loss: 7.5475, Train MAE: 2.1420, Train RMSE: 2.7035, Val Loss: 5.0154, Val MAE: 1.6574, Val RMSE: 2.1875\n",
      "New best validation loss: 5.0154 (previous best: 6.0860)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 3/100, Train Loss: 5.0161, Train MAE: 1.5855, Train RMSE: 2.1503, Val Loss: 2.5032, Val MAE: 1.3610, Val RMSE: 1.5689\n",
      "New best validation loss: 2.5032 (previous best: 5.0154)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 4/100, Train Loss: 0.7850, Train MAE: 0.6758, Train RMSE: 0.8299, Val Loss: 0.1418, Val MAE: 0.3103, Val RMSE: 0.3710\n",
      "New best validation loss: 0.1418 (previous best: 2.5032)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 5/100, Train Loss: 0.5099, Train MAE: 0.5458, Train RMSE: 0.6511, Val Loss: 1.5966, Val MAE: 1.2381, Val RMSE: 1.2619\n",
      "No improvement, patience left: 9\n",
      "Epoch 6/100, Train Loss: 0.4142, Train MAE: 0.5037, Train RMSE: 0.5923, Val Loss: 0.4358, Val MAE: 0.6409, Val RMSE: 0.6592\n",
      "No improvement, patience left: 8\n",
      "Epoch 7/100, Train Loss: 0.3885, Train MAE: 0.4875, Train RMSE: 0.5632, Val Loss: 0.4225, Val MAE: 0.6353, Val RMSE: 0.6494\n",
      "No improvement, patience left: 7\n",
      "Epoch 8/100, Train Loss: 0.3303, Train MAE: 0.4457, Train RMSE: 0.5090, Val Loss: 0.0317, Val MAE: 0.1313, Val RMSE: 0.1724\n",
      "New best validation loss: 0.0317 (previous best: 0.1418)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 9/100, Train Loss: 0.2985, Train MAE: 0.4276, Train RMSE: 0.4850, Val Loss: 0.0304, Val MAE: 0.1300, Val RMSE: 0.1696\n",
      "New best validation loss: 0.0304 (previous best: 0.0317)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 10/100, Train Loss: 0.2973, Train MAE: 0.4270, Train RMSE: 0.4831, Val Loss: 0.0288, Val MAE: 0.1273, Val RMSE: 0.1658\n",
      "New best validation loss: 0.0288 (previous best: 0.0304)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 11/100, Train Loss: 0.2953, Train MAE: 0.4254, Train RMSE: 0.4817, Val Loss: 0.0421, Val MAE: 0.1559, Val RMSE: 0.1994\n",
      "No improvement, patience left: 9\n",
      "Epoch 12/100, Train Loss: 0.2926, Train MAE: 0.4246, Train RMSE: 0.4794, Val Loss: 0.0290, Val MAE: 0.1300, Val RMSE: 0.1673\n",
      "No improvement, patience left: 8\n",
      "Epoch 13/100, Train Loss: 0.2883, Train MAE: 0.4228, Train RMSE: 0.4760, Val Loss: 0.0244, Val MAE: 0.1152, Val RMSE: 0.1517\n",
      "New best validation loss: 0.0244 (previous best: 0.0288)\n",
      "Model checkpoint saved at best_cpg_model_optuna.pth\n",
      "Epoch 14/100, Train Loss: 0.2876, Train MAE: 0.4212, Train RMSE: 0.4752, Val Loss: 0.0285, Val MAE: 0.1252, Val RMSE: 0.1637\n",
      "No improvement, patience left: 9\n",
      "Epoch 15/100, Train Loss: 0.2865, Train MAE: 0.4217, Train RMSE: 0.4731, Val Loss: 0.0249, Val MAE: 0.1197, Val RMSE: 0.1538\n",
      "No improvement, patience left: 8\n",
      "Epoch 16/100, Train Loss: 0.2829, Train MAE: 0.4178, Train RMSE: 0.4701, Val Loss: 0.0445, Val MAE: 0.1645, Val RMSE: 0.2059\n",
      "No improvement, patience left: 7\n",
      "Epoch 17/100, Train Loss: 0.2759, Train MAE: 0.4147, Train RMSE: 0.4638, Val Loss: 0.0328, Val MAE: 0.1595, Val RMSE: 0.1799\n",
      "No improvement, patience left: 6\n",
      "Epoch 18/100, Train Loss: 0.2719, Train MAE: 0.4108, Train RMSE: 0.4602, Val Loss: 0.0260, Val MAE: 0.1425, Val RMSE: 0.1602\n",
      "No improvement, patience left: 5\n",
      "Epoch 19/100, Train Loss: 0.2731, Train MAE: 0.4111, Train RMSE: 0.4620, Val Loss: 0.0296, Val MAE: 0.1538, Val RMSE: 0.1711\n",
      "No improvement, patience left: 4\n",
      "Epoch 20/100, Train Loss: 0.2711, Train MAE: 0.4107, Train RMSE: 0.4595, Val Loss: 0.0276, Val MAE: 0.1484, Val RMSE: 0.1653\n",
      "No improvement, patience left: 3\n",
      "Epoch 21/100, Train Loss: 0.2693, Train MAE: 0.4103, Train RMSE: 0.4578, Val Loss: 0.0282, Val MAE: 0.1510, Val RMSE: 0.1672\n",
      "No improvement, patience left: 2\n",
      "Epoch 22/100, Train Loss: 0.2703, Train MAE: 0.4093, Train RMSE: 0.4581, Val Loss: 0.0261, Val MAE: 0.1424, Val RMSE: 0.1605\n",
      "No improvement, patience left: 1\n",
      "Epoch 23/100, Train Loss: 0.2703, Train MAE: 0.4112, Train RMSE: 0.4594, Val Loss: 0.0294, Val MAE: 0.1535, Val RMSE: 0.1705\n",
      "No improvement, patience left: 0\n",
      "Early Stopping Triggered after epoch 23\n",
      "Training Completed in 85.47 seconds\n",
      "Loaded checkpoint from best_cpg_model_optuna.pth, resuming from epoch 13 with best validation loss: 0.0244\n"
     ]
    }
   ],
   "source": [
    "# Run Hyperparameter Tuning\n",
    "best_hyperparams, trained_model = tune_hyperparameters(\n",
    "    vocab_size,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    stop_patience,\n",
    "    n_trials=7,\n",
    "    save_best_model_path=\"best_cpg_model_optuna.pth\",\n",
    "    study_name=\"cpg_optuna\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNAACGGAGGTTGGGCGCANGTANTTGGACGNGCAACATNCNCGCTGTGNCACTCCNGGCACATGATNTGNNTGG\n",
      "[4]\n",
      "Voila! The hyper tuned model is working perfectly\n",
      "DNA: NNAACGGAGGTTGGGCGCANGTANTTGGACGNGCAACATNCNCGCTGTGNCACTCCNGGCACATGATNTGNNTGG \n",
      "ðŸ”¹ Predicted CpG Count: 3.97\n"
     ]
    }
   ],
   "source": [
    "# ABS NEW Test Example create a 128 length DNA sequence with 5 CG sites\n",
    "X_dna_seqs_train = list(rand_sequence_var_len(1, min_len, max_len))\n",
    "test_dna = [\"\".join(list(intseq_to_dnaseq(seq))) for seq in X_dna_seqs_train]\n",
    "y_dna_seqs = [count_cpgs(seq) for seq in test_dna]\n",
    "\n",
    "test_dna = test_dna[0]\n",
    "print(test_dna)\n",
    "print(y_dna_seqs)\n",
    "\n",
    "# test prediction from the advanced model\n",
    "predicted_cpgs = predict_cpgs_from_dna_pack_padded(\n",
    "    model_path=\"best_cpg_model_optuna.pth\",\n",
    "    dna_sequence=test_dna,\n",
    "    dna2int=dna2int,\n",
    "    embedding_dim=best_hyperparams[\"embedding_dim\"],\n",
    "    hidden_size=best_hyperparams[\"hidden_size\"],\n",
    "    num_layers=best_hyperparams[\"num_layers\"],\n",
    "    dropout=best_hyperparams[\"dropout\"],\n",
    "    device=device,\n",
    "    model_class=CpGCounterAdvancedPackPadding,\n",
    ")\n",
    "print(\"Voila! The hyper tuned model is working perfectly\")\n",
    "print(f\"DNA: {test_dna} \\nðŸ”¹ Predicted CpG Count: {predicted_cpgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Optuna what we are esentially doing:\n",
    "- Define the search space for hyperparameters.\n",
    "- Define the objective function to optimize.\n",
    "- Run the hyperparameter optimization process.\n",
    "- Train the best model with the optimized hyperparameters.\n",
    "- Evaluate the best model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEXT We will use the model to predict the CpG count from the DNA sequence using an fastapi app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [5458]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:57386 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57386 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57402 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:57378 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:49248 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [5458]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "\n",
    "\n",
    "# FastAPI app instance\n",
    "app = FastAPI(\n",
    "    title=\"CpG Island Counter\",\n",
    "    description=\"Predict the number of CpG islands in a DNA sequence\",\n",
    "    version=\"0.1\",\n",
    ")\n",
    "\n",
    "model_path = \"best_cpg_model_advanced_packpad.pth\"\n",
    "\n",
    "\n",
    "# Define the request schema\n",
    "class DNASequenceRequest(BaseModel):\n",
    "    dna_sequence: str\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"dna_sequence\": \"CCGTTTAANAATGATTAAACNGCCGTGCATACTGCANGGGNTATNNATTGGNNNCGAGTTANCNA\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "# define the response schema\n",
    "class DNASequenceResponse(BaseModel):\n",
    "    dna_sequence: str\n",
    "    predicted_cpg_count: float\n",
    "\n",
    "\n",
    "# heatbeat endpoint just checking if the model file exists\n",
    "@app.get(\"/heath\")\n",
    "def heath():\n",
    "    if os.path.exists(model_path):\n",
    "        return {\"status\": \"Model file found\"}\n",
    "    else:\n",
    "        raise HTTPException(\n",
    "            status_code=500, detail=\"Model file not found at {model_path}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Prediction endpoint\n",
    "@app.post(\"/predict\", response_model=DNASequenceResponse)\n",
    "def predict_cpg(request: DNASequenceRequest):\n",
    "    try:\n",
    "        predicted_cpgs = predict_cpgs_from_dna_pack_padded(\n",
    "            model_path,\n",
    "            request.dna_sequence,\n",
    "            dna2int,\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            dropout,\n",
    "            device,\n",
    "            model_class=CpGCounterAdvancedPackPadding,\n",
    "        )\n",
    "        return {\n",
    "            \"dna_sequence\": request.dna_sequence,\n",
    "            \"predicted_cpg_count\": predicted_cpgs,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################### END ####################################################################"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi Yangs Copy of broken-nn-template.ipynb",
   "provenance": [
    {
     "file_id": "13GlbI_pdKNES8I718iwl1KNnMZ73iOOn",
     "timestamp": 1651680757732
    }
   ]
  },
  "kernelspec": {
   "display_name": "emlo_env_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
